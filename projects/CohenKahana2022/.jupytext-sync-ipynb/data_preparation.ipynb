{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c2bfb8",
   "metadata": {},
   "source": [
    "# Cohen & Kahana (2022) → `RecallDataset` loader (percent notebook)\n",
    "\n",
    "This script prepares a rectangular, integer-only dataset from the raw\n",
    "Cohen & Kahana (2022) files for use in `jaxcmr`.\n",
    "\n",
    "The **output `RecallDataset`** has one row per trial and the following fields:\n",
    "\n",
    "- **`subject : (n_trials, 1)`**\n",
    "  Integer subject code (e.g., 93 for “LTP093”).\n",
    "\n",
    "- **`listLength : (n_trials, 1)`**\n",
    "  Actual number of non-zero presented items in the list.\n",
    "\n",
    "- **`pres_itemids : (n_trials, P)`**\n",
    "  Global item IDs presented on each trial, padded with zeros to the maximum list length.\n",
    "\n",
    "- **`pres_itemnos : (n_trials, P)`**\n",
    "  Within-list serial positions 1..L for each presented item, padded with zeros.\n",
    "\n",
    "- **`rec_itemids : (n_trials, R)`**\n",
    "  Raw recalled item IDs after filtering. Intrusions may be dropped or retained depending on config flags. Padded with zeros to the maximum recall length.\n",
    "\n",
    "- **`recalls : (n_trials, R)`**\n",
    "  Within-list serial positions of recalled items, padded with zeros.\n",
    "  - In-list recalls: positive serial position (1..L).\n",
    "  - Extra-list intrusions (ELIs) that are **kept**: `rec_itemids > 0` but `recalls == 0`.\n",
    "  - Padding: `rec_itemids == 0` and `recalls == 0`.\n",
    "\n",
    "- **`valence : (n_trials, P)`**\n",
    "  Emotional valence codes (−1, 0, +1) aligned with `pres_itemids`.\n",
    "\n",
    "- **`session : (n_trials, 1)`**\n",
    "  Session index (1-based), assuming exactly 24 lists per session.\n",
    "\n",
    "## Conversion issues addressed\n",
    "\n",
    "- **Intrusions**\n",
    "  - **Negatives (−1)** and **zeros** in recall sequences are always dropped.\n",
    "  - **ELIs** (positive IDs not in the current list):\n",
    "    - If `FILTER_ELIS=True`, they are dropped.\n",
    "    - If `FILTER_ELIS=False`, they are preserved in `rec_itemids` and marked with `recalls == 0`.\n",
    "    This makes them distinguishable from padding by the joint condition:\n",
    "    `rec_itemids > 0 & recalls == 0`.\n",
    "\n",
    "- **Repeated recalls of the same item**\n",
    "  Controlled by `FILTER_REPEATED_RECALLS`.\n",
    "  - If `True`, only the first recall of an item is kept.\n",
    "  - If `False`, all repeats are retained.\n",
    "  This applies to **any** repeats, not just immediate ones.\n",
    "\n",
    "- **Mapping recalls to positions**\n",
    "  Each recalled ID is mapped to the **first** presentation of that ID within the study list.\n",
    "  This matches the CMR family’s convention. If the recalled ID was not presented in the list (ELI kept), its position is recorded as 0.\n",
    "\n",
    "- **Zeros in the middle of recall sequences**\n",
    "  These are treated as anomalies; the validator warns but the loader filters them like intrusions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from jaxcmr.helpers import save_dict_to_hdf5\n",
    "from jaxcmr.typing import RecallDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0ca945",
   "metadata": {},
   "source": [
    "## 1) Config toggles & invariants\n",
    "- `KEEP_SUCCESSIVE_PERSEVERATIONS`: if `False`, drops **only** immediate repeats (A A → keep first A, drop second).\n",
    "- `SESSION_LISTS`: hard assumption: every valid subject has `n_lists % 24 == 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True, remove any repeated recall of the same item within a trial\n",
    "# (A ... A) — not just immediate repeats.\n",
    "FILTER_REPEATED_RECALLS: bool = True\n",
    "\n",
    "# If True, drop out-of-list intrusions (positive IDs not in the presented set).\n",
    "FILTER_ELIS: bool = True\n",
    "\n",
    "# Fatal guard: every subject must have lists multiple of this session size\n",
    "SESSION_LISTS: int = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ae1870",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 3) Validation report dataclasses\n",
    "These are simple containers for returning structured information from the validators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91acfd3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RawValidationReport:\n",
    "    subjects_checked: int\n",
    "    fatal_issues: List[str]\n",
    "    warnings: List[str]\n",
    "    # counters aggregated across subjects\n",
    "    total_subjects_missing_files: int\n",
    "    total_row_count_mismatches: int\n",
    "    total_pres_eval_width_mismatches: int\n",
    "    total_non_multiple_of_session: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DatasetValidationReport:\n",
    "    n_trials: int\n",
    "    num_presented_max: int\n",
    "    num_recalled_max: int\n",
    "    # filtered counts are not directly reconstructable post-hoc\n",
    "    filtered_neg_intrusions: int\n",
    "    filtered_zero_intrusions: int\n",
    "    filtered_eli_intrusions: int\n",
    "    filtered_successive_perseverations: int\n",
    "    # structural checks\n",
    "    recalls_within_bounds: bool\n",
    "    mapping_uses_first_presentation: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464cae1b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 4) Small utilities (CSV parsing, labels)\n",
    "Keep these lean and predictable — no hidden behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc2325",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def _parse_valid_labels(valid_list_path: Path) -> List[str]:\n",
    "    \"\"\"Return labels like 'LTP093' from the valid-subjects list.\n",
    "    Accepts either 'LTP093' or a bare number like '93'.\"\"\"\n",
    "    labels: List[str] = []\n",
    "    for ln in valid_list_path.read_text().splitlines():\n",
    "        tok = ln.strip()\n",
    "        if not tok:\n",
    "            continue\n",
    "        if tok.upper().startswith(\"LTP\"):\n",
    "            labels.append(tok.upper())\n",
    "        else:\n",
    "            num = int(\"\".join(ch for ch in tok if ch.isdigit()))\n",
    "            labels.append(f\"LTP{num:03d}\")\n",
    "    return labels\n",
    "\n",
    "\n",
    "def _subject_int_from_label(label: str) -> int:\n",
    "    \"\"\"Map 'LTP093' → 93 (int).\"\"\"\n",
    "    digits = \"\".join(ch for ch in label if ch.isdigit())\n",
    "    return int(digits)\n",
    "\n",
    "\n",
    "def _read_csv_matrix(path: Path) -> List[List[int]]:\n",
    "    \"\"\"Parse a comma-separated integer matrix file into a list of int lists.\n",
    "    Skips blank lines (e.g., trailing blank line).\"\"\"\n",
    "    rows: List[List[int]] = []\n",
    "    for ln in path.read_text().splitlines():\n",
    "        ln = ln.strip()\n",
    "        if not ln:\n",
    "            continue\n",
    "        row = [int(tok.strip()) for tok in ln.split(\",\") if tok.strip() != \"\"]\n",
    "        rows.append(row)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14fad3e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 5) Preflight raw validation (raises on fatal)\n",
    "Checks across **pres/rec/eval** for each valid subject:\n",
    "- Missing files\n",
    "- Row count mismatches\n",
    "- Per‑trial width mismatch between `pres` and `eval`\n",
    "- Lists not a multiple of 24 (session size)\n",
    "\n",
    "Soft warnings only (do not raise):\n",
    "- Zeros in the *middle* of recall sequences\n",
    "- Positive recalls not in presentations (ELIs)\n",
    "- Negative recalls present\n",
    "- Valence codes outside {−1,0,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4f1a7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def validate_raw_cohen_kahana_2022(raw_dir: Path | str) -> RawValidationReport:\n",
    "    raw_path = Path(raw_dir)\n",
    "    valid_list_path = raw_path / \"valid_subjects_list.txt\"\n",
    "    if not valid_list_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing valid subjects list: {valid_list_path}\")\n",
    "\n",
    "    pres_dir = raw_path / \"pres_files\"\n",
    "    rec_dir = raw_path / \"rec_files\"\n",
    "    eval_dir = raw_path / \"eval_files\"\n",
    "\n",
    "    labels = _parse_valid_labels(valid_list_path)\n",
    "\n",
    "    fatal_issues: List[str] = []\n",
    "    warnings: List[str] = []\n",
    "    missing_files = 0\n",
    "    row_mismatches = 0\n",
    "    width_mismatches = 0\n",
    "    non_multiple = 0\n",
    "\n",
    "    for label in labels:\n",
    "        pres_path = pres_dir / f\"pres_nos_{label}.txt\"\n",
    "        rec_path = rec_dir / f\"rec_nos_{label}.txt\"\n",
    "        eval_path = eval_dir / f\"eval_codes_{label}.txt\"\n",
    "\n",
    "        missing_this = False\n",
    "        for p in (pres_path, rec_path, eval_path):\n",
    "            if not p.exists():\n",
    "                missing_files += 1\n",
    "                missing_this = True\n",
    "                fatal_issues.append(f\"Missing file for {label}: {p}\")\n",
    "        if missing_this:\n",
    "            continue  # skip this subject only\n",
    "\n",
    "        pres_rows = _read_csv_matrix(pres_path)\n",
    "        rec_rows = _read_csv_matrix(rec_path)\n",
    "        eval_rows = _read_csv_matrix(eval_path)\n",
    "\n",
    "        # Row counts\n",
    "        if not (len(pres_rows) == len(rec_rows) == len(eval_rows)):\n",
    "            row_mismatches += 1\n",
    "            fatal_issues.append(\n",
    "                f\"Row count mismatch for {label}: pres={len(pres_rows)} rec={len(rec_rows)} eval={len(eval_rows)}\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        n_lists = len(pres_rows)\n",
    "        if n_lists % SESSION_LISTS != 0:\n",
    "            non_multiple += 1\n",
    "            fatal_issues.append(\n",
    "                f\"Lists not multiple of {SESSION_LISTS} for {label}: n_lists={n_lists}\"\n",
    "            )\n",
    "\n",
    "        # Per-trial checks\n",
    "        for i, (p_row, r_row, e_row) in enumerate(zip(pres_rows, rec_rows, eval_rows)):\n",
    "            # pres <-> eval width\n",
    "            if len(p_row) != len(e_row):\n",
    "                width_mismatches += 1\n",
    "                fatal_issues.append(\n",
    "                    f\"Width mismatch {label} trial {i}: pres width={len(p_row)} vs eval width={len(e_row)}\"\n",
    "                )\n",
    "\n",
    "            # Soft warnings on recalls\n",
    "            # zero in the middle (before a later non-zero)\n",
    "            if any(\n",
    "                (rv == 0 and any(x != 0 for x in r_row[j + 1 :]))\n",
    "                for j, rv in enumerate(r_row)\n",
    "            ):\n",
    "                warnings.append(f\"Zeros in middle of recall seq: {label} trial {i}\")\n",
    "\n",
    "            pset = set(x for x in p_row if x > 0)\n",
    "            if any((rv > 0 and rv not in pset) for rv in r_row):\n",
    "                warnings.append(f\"ELI intrusions present: {label} trial {i}\")\n",
    "            if any(rv < 0 for rv in r_row):\n",
    "                warnings.append(f\"Negative intrusions present: {label} trial {i}\")\n",
    "\n",
    "            if any(ev not in (-1, 0, 1) for ev in e_row):\n",
    "                warnings.append(f\"Non {-1, 0, 1} valence code: {label} trial {i}\")\n",
    "\n",
    "    if missing_files or row_mismatches or width_mismatches or non_multiple:\n",
    "        raise ValueError(\n",
    "            \"\\n\".join(\n",
    "                [\n",
    "                    \"Fatal raw-data issues detected:\",\n",
    "                    *fatal_issues,\n",
    "                    \"-- end fatal issues --\",\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return RawValidationReport(\n",
    "        subjects_checked=len(labels),\n",
    "        fatal_issues=fatal_issues,\n",
    "        warnings=warnings,\n",
    "        total_subjects_missing_files=missing_files,\n",
    "        total_row_count_mismatches=row_mismatches,\n",
    "        total_pres_eval_width_mismatches=width_mismatches,\n",
    "        total_non_multiple_of_session=non_multiple,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1459d6d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 6) Core loader\n",
    "- Includes **intrusion filtering** and the **first‑presentation** mapping for `recalls`.\n",
    "- Computes `listLength` as the count of non‑zero `pres_itemids` per trial.\n",
    "- Pads to dataset‑level maxima with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e8527",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def load_cohen_kahana_2022(\n",
    "    raw_dir: Path | str,\n",
    "    filter_repeated_recalls: bool | None = None,\n",
    "    filter_elis: bool | None = None,\n",
    ") -> RecallDataset:\n",
    "    \"\"\"Load the dataset into a rectangular `RecallDataset` (integer arrays only).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_dir : Path | str\n",
    "        Path to `data/raw/CohenKahana2022` with subdirs `pres_files/`, `rec_files/`,\n",
    "        `eval_files/`, and `valid_subjects_list.txt`.\n",
    "    keep_successive_perseverations : bool | None\n",
    "        If given, overrides module-level `KEEP_SUCCESSIVE_PERSEVERATIONS`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    RecallDataset\n",
    "        Dict of 2D `jnp.int32` arrays with required and optional fields.\n",
    "    \"\"\"\n",
    "    raw_path = Path(raw_dir)\n",
    "    if filter_repeated_recalls is None:\n",
    "        filter_repeated_recalls = FILTER_REPEATED_RECALLS\n",
    "    if filter_elis is None:\n",
    "        filter_elis = FILTER_ELIS\n",
    "\n",
    "    valid_list_path = raw_path / \"valid_subjects_list.txt\"\n",
    "    pres_dir = raw_path / \"pres_files\"\n",
    "    rec_dir = raw_path / \"rec_files\"\n",
    "    eval_dir = raw_path / \"eval_files\"\n",
    "\n",
    "    labels = _parse_valid_labels(valid_list_path)\n",
    "\n",
    "    # First pass: collect variable-length rows; compute maxima\n",
    "    all_pres: List[List[int]] = []\n",
    "    all_rec_filtered_ids: List[List[int]] = []\n",
    "    all_rec_mapped_pos: List[List[int]] = []\n",
    "    all_valence: List[List[int]] = []\n",
    "\n",
    "    subject_vec: List[int] = []\n",
    "    session_vec: List[int] = []\n",
    "    list_len_vec: List[int] = []\n",
    "\n",
    "    num_presented_max = 0\n",
    "    num_recalled_max = 0\n",
    "\n",
    "    for label in labels:\n",
    "        pres_path = pres_dir / f\"pres_nos_{label}.txt\"\n",
    "        rec_path = rec_dir / f\"rec_nos_{label}.txt\"\n",
    "        eval_path = eval_dir / f\"eval_codes_{label}.txt\"\n",
    "\n",
    "        pres_rows = _read_csv_matrix(pres_path)\n",
    "        rec_rows = _read_csv_matrix(rec_path)\n",
    "        eval_rows = _read_csv_matrix(eval_path)\n",
    "\n",
    "        # Strong guards (mirror preflight)\n",
    "        assert len(pres_rows) == len(rec_rows) == len(eval_rows), (\n",
    "            f\"Row count mismatch for {label}: pres={len(pres_rows)} rec={len(rec_rows)} eval={len(eval_rows)}\"\n",
    "        )\n",
    "        n_lists = len(pres_rows)\n",
    "        assert n_lists % SESSION_LISTS == 0, (\n",
    "            f\"Lists not multiple of {SESSION_LISTS} for {label}: n_lists={n_lists}\"\n",
    "        )\n",
    "\n",
    "        subj_int = _subject_int_from_label(label)\n",
    "\n",
    "        for idx, (p_row, r_row, e_row) in enumerate(\n",
    "            zip(pres_rows, rec_rows, eval_rows)\n",
    "        ):\n",
    "            # width alignment pres <-> eval\n",
    "            if len(p_row) != len(e_row):\n",
    "                raise ValueError(\n",
    "                    f\"Width mismatch {label} trial {idx}: pres width={len(p_row)} vs eval width={len(e_row)}\"\n",
    "                )\n",
    "\n",
    "            # list length = count of non-zero presented IDs\n",
    "            L = sum(1 for x in p_row if x > 0)\n",
    "            list_len_vec.append(L)\n",
    "            session_idx = (idx // SESSION_LISTS) + 1  # 1-based\n",
    "            session_vec.append(session_idx)\n",
    "            subject_vec.append(subj_int)\n",
    "\n",
    "            all_pres.append(p_row)\n",
    "            all_valence.append(e_row)\n",
    "\n",
    "            # Map ID -> FIRST presentation position (1-based)\n",
    "            first_pos: Dict[int, int] = {}\n",
    "            pos_counter = 0\n",
    "            for x in p_row:\n",
    "                if x > 0:\n",
    "                    pos_counter += 1\n",
    "                    if x not in first_pos:\n",
    "                        first_pos[x] = pos_counter\n",
    "\n",
    "            # Filter recalls: drop negatives/zeros; optionally drop ELIs; optionally drop ANY repeats\n",
    "            filtered_ids: List[int] = []\n",
    "            seen_ids: set[int] = set()\n",
    "            pset = set(first_pos.keys())\n",
    "\n",
    "            for rv in r_row:\n",
    "                # negatives and zeros are always dropped\n",
    "                if rv <= 0:\n",
    "                    continue\n",
    "\n",
    "                # out-of-list intrusion?\n",
    "                if rv not in pset:\n",
    "                    if filter_elis:\n",
    "                        continue\n",
    "                    # else keep the ELI in rec_itemids; it will not map to a within-list position\n",
    "                    # (we'll handle its 'recalls' value as 0 below)\n",
    "\n",
    "                # repeated recall?\n",
    "                if filter_repeated_recalls and rv in seen_ids:\n",
    "                    continue\n",
    "\n",
    "                filtered_ids.append(rv)\n",
    "                seen_ids.add(rv)\n",
    "\n",
    "            mapped_pos = [first_pos.get(rv, 0) for rv in filtered_ids]\n",
    "\n",
    "            all_rec_filtered_ids.append(filtered_ids)\n",
    "            all_rec_mapped_pos.append(mapped_pos)\n",
    "\n",
    "            num_presented_max = max(num_presented_max, len(p_row))\n",
    "            num_recalled_max = max(num_recalled_max, len(filtered_ids))\n",
    "\n",
    "    # Second pass: pad to maxima and assemble arrays\n",
    "    n_trials = len(all_pres)\n",
    "    pres_itemids = np.zeros((n_trials, num_presented_max), dtype=np.int32)\n",
    "    pres_itemnos = np.zeros((n_trials, num_presented_max), dtype=np.int32)\n",
    "    valence = np.zeros((n_trials, num_presented_max), dtype=np.int32)\n",
    "\n",
    "    rec_itemids = np.zeros((n_trials, num_recalled_max), dtype=np.int32)\n",
    "    recalls = np.zeros((n_trials, num_recalled_max), dtype=np.int32)\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        prow = all_pres[i]\n",
    "        vrow = all_valence[i]\n",
    "        L = sum(1 for x in prow if x > 0)\n",
    "\n",
    "        # Presented IDs & valence\n",
    "        pres_itemids[i, : len(prow)] = np.asarray(prow, dtype=np.int32)\n",
    "        valence[i, : len(vrow)] = np.asarray(vrow, dtype=np.int32)\n",
    "\n",
    "        # Within-list positions 1..L (0 for padding)\n",
    "        if L > 0:\n",
    "            pres_itemnos[i, :L] = np.arange(1, L + 1, dtype=np.int32)\n",
    "\n",
    "        # Recalls\n",
    "        rid_row = all_rec_filtered_ids[i]\n",
    "        rpos_row = all_rec_mapped_pos[i]\n",
    "        if rid_row:\n",
    "            rec_itemids[i, : len(rid_row)] = np.asarray(rid_row, dtype=np.int32)\n",
    "            recalls[i, : len(rpos_row)] = np.asarray(rpos_row, dtype=np.int32)\n",
    "\n",
    "    subject = jnp.asarray(np.asarray(subject_vec, dtype=np.int32).reshape(n_trials, 1))\n",
    "    session = jnp.asarray(np.asarray(session_vec, dtype=np.int32).reshape(n_trials, 1))\n",
    "    listLength = jnp.asarray(\n",
    "        np.asarray(list_len_vec, dtype=np.int32).reshape(n_trials, 1)\n",
    "    )\n",
    "\n",
    "    ds: RecallDataset = {\n",
    "        \"subject\": subject,\n",
    "        \"listLength\": listLength,\n",
    "        \"pres_itemids\": jnp.asarray(pres_itemids),\n",
    "        \"pres_itemnos\": jnp.asarray(pres_itemnos),\n",
    "        \"rec_itemids\": jnp.asarray(rec_itemids),\n",
    "        \"recalls\": jnp.asarray(recalls),\n",
    "        \"valence\": jnp.asarray(valence),\n",
    "        \"session\": session,\n",
    "    }\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54544dc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 7) Post‑hoc dataset validation\n",
    "Lightweight checks on the *constructed* arrays:\n",
    "- `recalls` within `[0, listLength]`\n",
    "- `rec_itemids[i,j]` maps to the **first** presentation at `recalls[i,j]`\n",
    "\n",
    "Note: We do **not** attempt to reconstruct exact counts of filtered events; we report −1 as a sentinel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c0e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_RecallDataset(ds: RecallDataset) -> DatasetValidationReport:\n",
    "    subject = np.asarray(ds[\"subject\"])  # (n_trials, 1)\n",
    "    list_len = np.asarray(ds[\"listLength\"]).reshape(-1)\n",
    "    pres_ids = np.asarray(ds[\"pres_itemids\"])  # (n_trials, P)\n",
    "    rec_ids = np.asarray(ds[\"rec_itemids\"])  # (n_trials, R)\n",
    "    recalls = np.asarray(ds[\"recalls\"])  # (n_trials, R)\n",
    "\n",
    "    n_trials, num_presented_max = pres_ids.shape\n",
    "    _, num_recalled_max = rec_ids.shape\n",
    "\n",
    "    # bounds check: recalls in [0, listLength]\n",
    "    max_per_row = list_len[:, None]\n",
    "    recalls_within = ((recalls >= 0) & (recalls <= max_per_row)).all()\n",
    "\n",
    "    # first-presentation mapping check\n",
    "    first_ok = True\n",
    "    for i in range(n_trials):\n",
    "        first_pos: Dict[int, int] = {}\n",
    "        pos = 0\n",
    "        for x in pres_ids[i]:\n",
    "            if x > 0:\n",
    "                pos += 1\n",
    "                if x not in first_pos:\n",
    "                    first_pos[x] = pos\n",
    "        for rid, rpos in zip(rec_ids[i], recalls[i]):\n",
    "            if rid == 0 and rpos == 0:\n",
    "                continue  # padding\n",
    "            elif rid == 0:\n",
    "                first_ok = False\n",
    "                break\n",
    "            elif rpos == 0:\n",
    "                # allow only if not an in-list ID (i.e., kept ELI)\n",
    "                if rid in first_pos:\n",
    "                    first_ok = False\n",
    "                    break\n",
    "            elif first_pos.get(rid) != int(rpos):\n",
    "                first_ok = False\n",
    "                break\n",
    "\n",
    "    # We cannot directly count filtered tokens post-hoc; set sentinels\n",
    "    filtered_neg = -1\n",
    "    filtered_zero = -1\n",
    "    filtered_eli = -1\n",
    "    filtered_persev = -1\n",
    "\n",
    "    return DatasetValidationReport(\n",
    "        n_trials=n_trials,\n",
    "        num_presented_max=num_presented_max,\n",
    "        num_recalled_max=num_recalled_max,\n",
    "        filtered_neg_intrusions=filtered_neg,\n",
    "        filtered_zero_intrusions=filtered_zero,\n",
    "        filtered_eli_intrusions=filtered_eli,\n",
    "        filtered_successive_perseverations=filtered_persev,\n",
    "        recalls_within_bounds=bool(recalls_within),\n",
    "        mapping_uses_first_presentation=bool(first_ok),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d6478",
   "metadata": {},
   "source": [
    "## 8) Quick‑start usage\n",
    "This mirrors the intended workflow without entangling validation with loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3125ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    raw = Path(\"data/raw/CohenKahana2022\")\n",
    "    data_tag = \"CohenKahana2022\"\n",
    "    preflight = validate_raw_cohen_kahana_2022(raw)  # raises on fatal issues\n",
    "\n",
    "    for filter_elis in (True, False):\n",
    "        filter_tag = \"noELI\" if filter_elis else \"withELI\"\n",
    "        ds = load_cohen_kahana_2022(\n",
    "            raw,\n",
    "            filter_repeated_recalls=FILTER_REPEATED_RECALLS,\n",
    "            filter_elis=filter_elis,\n",
    "        )\n",
    "        report = validate_RecallDataset(ds)\n",
    "        save_dict_to_hdf5(ds, f\"data/{data_tag}_{filter_tag}.h5\")\n",
    "        print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152961f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": ".jupytext-sync-ipynb//ipynb,py:percent",
   "main_language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
