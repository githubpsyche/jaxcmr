{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbf41c15-cb72-4e57-8739-2d4274c45d6e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " # Lohnas & Kahana, 2014 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31542d-5291-459a-a26f-5262ee135b3a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " > Siegel, L. L., & Kahana, M. J. (2014). A retrieved context account of spacing and repetition effects in free recall. Journal of Experimental Psychology: Learning, Memory, and Cognition, 40(3), 755.\n",
    "\n",
    " Across 4 sessions, 35 subjects performed delayed free recall of 48 lists. Subjects were University of Pennsylvania undergraduates, graduates and staff, age 18-32. List items were drawn from a pool of 1638 words taken from the University of South Florida free association norms (Nelson, McEvoy, & Schreiber, 2004; Steyvers, Shiffrin, & Nelson, 2004, available at http://memory.psych.upenn.edu/files/wordpools/PEERS_wordpool.zip). Within each session, words were drawn without replacement. Words could repeat across sessions so long as they did not repeat in two successive sessions. Words were also selected to ensure that no strong semantic associates co-occurred in a given list (i.e., the semantic relatedness between any two words on a given list, as determined using WAS (Steyvers et al., 2004), did not exceed a threshold value of 0.55).\n",
    "\n",
    " Subjects encountered four different types of lists:\n",
    " 1. Control lists that contained all once-presented items;\n",
    " 2. pure massed lists containing all twice-presented items;\n",
    " 3. pure spaced lists consisting of items presented twice at lags 1-8, where lag is defined as the number of intervening items between a repeated item's presentations;\n",
    " 4. mixed lists consisting of once presented, massed and spaced items. Within each session, subjects encountered three lists of each of these four types.\n",
    "\n",
    " In each list there were 40 presentation positions, such that in the control lists each position was occupied by a unique list item, and in the pure massed and pure spaced lists, 20 unique words were presented twice to occupy the 40 positions. In the mixed lists 28 once-presented and six twice-presented words occupied the 40 positions. In the pure spaced lists, spacings of repeated items were chosen so that each of the lags 1-8 occurred with equal probability. In the mixed lists, massed repetitions (lag=0) and spaced repetitions (lags 1-8) were chosen such that each of the 9 lags of 0-8 were used exactly twice within each session. The order of presentation for the different list types was randomized within each session. For the first session, the first four lists were chosen so that each list type was presented exactly once. An experimenter sat in with the subject for these first four lists, though no subject had difficulty understanding the task.\n",
    "\n",
    " Here, we read these raw data from `repFR.mat` and transform them into a Python dictionary\n",
    " adhering to the JAXCMR [RecallDataset protocol](#RecallDataset-Protocol), described below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c47a9-43a6-45bc-b871-97b92575ca35",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## 1. Loading the Raw `repFR.mat` File\n",
    "\n",
    " We use `scipy.io.loadmat` to read the .mat file. The `mat_file[\"data\"]` field\n",
    " holds an array of objects, from which we extract relevant fields.\n",
    " The file contains:\n",
    "\n",
    " - **Subjects**: Identifiers for each trial.\n",
    " - **Sessions**: Session indicators for each trial.\n",
    " - **Recalled items**: Indices and times.\n",
    " - **Presented items**: Indices at each presentation position.\n",
    " - **Other**: Additional info like list type, etc.\n",
    "\n",
    " We store them in Python lists and then progressively transform them into\n",
    " integer arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a309bdfe-8471-443d-8e3c-b8e7f19bacac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Length = 40\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from jaxcmr.helpers import save_dict_to_hdf5\n",
    "\n",
    "# Path to the raw .mat file\n",
    "path = 'data/raw/repFR.mat'\n",
    "# Load the .mat file (with squeeze_me=True to reduce dimensionality)\n",
    "mat_file = sio.loadmat(path, squeeze_me=True)\n",
    "\n",
    "# 'data' is an array of objects in the .mat file\n",
    "# We convert it to a Python list for easier indexing\n",
    "mat_data = [mat_file['data'].item()[i] for i in range(14)]\n",
    "\n",
    "# The total list length is constant for each trial\n",
    "list_length = mat_data[12]\n",
    "print(\"List Length =\", list_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d3e38-4417-4fb0-bf21-d68f8612b741",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## 2. Constructing Presented Items\n",
    "\n",
    " We have arrays indicating which item IDs were shown at each presentation position\n",
    "\n",
    " Next, we translate these \"raw IDs\" into *within-list* item numbers (`pres_itemnos`)\n",
    " in a way that each new *unique* item encountered in a trial is assigned a new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c213377a-79a9-43fa-8947-a197adb8515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of presentations = (1680, 40)\n"
     ]
    }
   ],
   "source": [
    "pres_itemnos_raw = mat_data[4].astype('int64')  # shape: (n_trials, positions)\n",
    "\n",
    "presentations = []  # We'll fill as a Python list-of-lists, then convert to np.array\n",
    "\n",
    "for i in range(len(pres_itemnos_raw)):\n",
    "    seen = []\n",
    "    presentations.append([])\n",
    "    for p in pres_itemnos_raw[i]:\n",
    "        if p not in seen:\n",
    "            seen.append(p)\n",
    "        # 'pres_itemnos' is the index of p in the \"seen\" array\n",
    "        presentations[-1].append(seen.index(p))\n",
    "\n",
    "presentations = np.array(presentations)+1\n",
    "print(\"Shape of presentations =\", presentations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400cc324-3f89-4c1b-a4af-5d80343d549b",
   "metadata": {},
   "source": [
    " ## 3. Constructing Recalls\n",
    "\n",
    " We have the `rec_itemnos` that identifies which item was recalled, and `recalls`\n",
    " that gives the recall order (1-based in MATLAB). We also have the time of recall.\n",
    "\n",
    "We need to transform these into a format that is more convenient for analysis.\n",
    "Each nonzero value in our `trials` array will track the first study position of each recalled item in its trial.\n",
    "Each nonzero value in our `trial_items` array will track the cross-trial item index of the recalled item.\n",
    "And finally, each nonzero value in our `trial_irts` array will track the inter-recall time of the recalled item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285960e5-6959-4dc2-8c27-6d0640fd6dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of trials = (1680, 40)\n",
      "Shape of trial_items = (1680, 40)\n"
     ]
    }
   ],
   "source": [
    "list_length = mat_data[12]\n",
    "rec_itemids_raw = mat_data[2].astype('int64')\n",
    "recalls_raw = mat_data[6]\n",
    "irt_raw = mat_data[3].astype('int64')\n",
    "\n",
    "trials = []\n",
    "trial_items = []\n",
    "trial_irts = []\n",
    "\n",
    "for i in range(len(recalls_raw)):\n",
    "    trials.append([])\n",
    "    trial_items.append([])\n",
    "    trial_irts.append([])\n",
    "\n",
    "    trial = list(recalls_raw[i])\n",
    "    for j in range(len(trial)):\n",
    "        t = trial[j]  # The recall (1-based from MATLAB)\n",
    "        trial_item = rec_itemids_raw[i][j]  # The cross-list ID\n",
    "        rt = irt_raw[i][j]  # The recall time\n",
    "        # Exclude 0 or negative values and repeated items in the same trial\n",
    "        if (t > 0) and (t not in trials[-1]):\n",
    "            trials[-1].append(t)\n",
    "            trial_items[-1].append(trial_item)\n",
    "            trial_irts[-1].append(rt)\n",
    "\n",
    "\n",
    "    # Pad up to the known list_length with zeros\n",
    "    while len(trials[-1]) < list_length:\n",
    "        trials[-1].append(0)\n",
    "        trial_items[-1].append(0)\n",
    "        trial_irts[-1].append(0)\n",
    "\n",
    "trials = np.array(trials, dtype='int64')\n",
    "trial_items = np.array(trial_items, dtype='int64')\n",
    "trial_irts = np.array(trial_irts, dtype='int64')\n",
    "print(\"Shape of trials =\", trials.shape)\n",
    "print(\"Shape of trial_items =\", trial_items.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9267e759-01d7-4ceb-9938-21452e7dd51a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## 4. Constructing the Final Result Dictionary\n",
    "\n",
    " We now assemble all the fields into a single dictionary called `result`.\n",
    "\n",
    " All arrays are `int64` and 2D, with zero-padding for unused entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee67e2c-afb2-4868-a999-1eacba623a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional fields from mat_data\n",
    "subject = np.expand_dims(mat_data[0].astype('int64'), axis=1)\n",
    "session = np.expand_dims(mat_data[1].astype('int64'), axis=1)+1\n",
    "list_type = np.expand_dims(mat_data[7].astype('int64'), axis=1)\n",
    "list_length = np.expand_dims(np.ones(np.shape(mat_data[0]), dtype=\"int64\"), axis=1) * 40\n",
    "pres_itemids = mat_data[4].astype('int64')\n",
    "\n",
    "result = {\n",
    "    \"subject\":      subject,            # (n_trials, 1)\n",
    "    \"session\":      session,            # (n_trials, 1) - optional\n",
    "    #'pres_items': mat_data[2],\n",
    "    #'rec_items':  mat_data[2],\n",
    "    \"pres_itemnos\": presentations,      # (n_trials, ?)\n",
    "    \"pres_itemids\": pres_itemids,       # (n_trials, ?)\n",
    "    \"rec_itemids\":  trial_items,        # (n_trials, ?)\n",
    "    \"recalls\":      trials,             # (n_trials, ?)\n",
    "    \"listLength\":   list_length,        # (n_trials, 1)\n",
    "    \"list_type\":    list_type,          # (n_trials, 1)\n",
    "    \"irt\":          trial_irts,                # (n_trials, ?)\n",
    "    #'pres_lag': \n",
    "    #'recalls_lag':\n",
    "    #'trial': mat_data[9].astype('int64'),\n",
    "    #'intrusions': \n",
    "    #'subject_sess':\n",
    "    #'massed_recalls':\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e986383-c6a5-4e59-91b3-5f26ae836d0d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## 5. Verifying the Result\n",
    "\n",
    " We check the shape and type of each field in the `result` dictionary.\n",
    " We also check the maximum and minimum values for each field.\n",
    " This is a good practice to ensure that the data is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a8470b0-e6e2-4101-b8ea-7852873aac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject -> (1680, 1) int64\n",
      "[[1]]\n",
      "Max value in subject: 37\n",
      "Min value in subject: 1\n",
      "\n",
      "session -> (1680, 1) int64\n",
      "[[1]]\n",
      "Max value in session: 4\n",
      "Min value in session: 1\n",
      "\n",
      "pres_itemnos -> (1680, 40) int64\n",
      "[[ 1  2  3  4  5  6  7  8  9 10 11 12 12 13 14 15 16 17 10 18 19 20 19 21\n",
      "  22 23 20 24 25 26 22 27 28 24 29 30 31 32 33 34]]\n",
      "Max value in pres_itemnos: 40\n",
      "Min value in pres_itemnos: 1\n",
      "\n",
      "pres_itemids -> (1680, 40) int64\n",
      "[[1585  886 1045  695  809   39 1636  358  249  692 1029  919  919  955\n",
      "  1407  745   81   19  692  321  279  170  279  212  639  840  170  302\n",
      "  1025  364  639  698  696  302 1562  819  105 1559  887  187]]\n",
      "Max value in pres_itemids: 1638\n",
      "Min value in pres_itemids: 1\n",
      "\n",
      "rec_itemids -> (1680, 40) int64\n",
      "[[1585  886 1045  695  809   39 1636  249  692 1029   81  955  919 1407\n",
      "   639  321  302  364  887 1559  105   19    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "Max value in rec_itemids: 1638\n",
      "Min value in rec_itemids: 0\n",
      "\n",
      "recalls -> (1680, 40) int64\n",
      "[[ 1  2  3  4  5  6  7  9 10 11 17 14 12 15 25 20 28 30 39 38 37 18  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Max value in recalls: 40\n",
      "Min value in recalls: 0\n",
      "\n",
      "listLength -> (1680, 1) int64\n",
      "[[40]]\n",
      "Max value in listLength: 40\n",
      "Min value in listLength: 40\n",
      "\n",
      "list_type -> (1680, 1) int64\n",
      "[[4]]\n",
      "Max value in list_type: 4\n",
      "Min value in list_type: 1\n",
      "\n",
      "irt -> (1680, 40) int64\n",
      "[[ 3408  4503  6178  7606  9039 10879 12303 14846 16379 20022 21951 24718\n",
      "  26083 27889 29753 31468 36133 38638 40034 41783 46099 49260     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Max value in irt: 89732\n",
      "Min value in irt: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a short summary\n",
    "for k, v in result.items():\n",
    "    print(k, \"->\", np.shape(v), v.dtype)\n",
    "    print(v[:1])  # Print first two entries for each field\n",
    "    print(f\"Max value in {k}:\", np.max(v))\n",
    "    print(f\"Min value in {k}:\", np.min(v))\n",
    "    print()\n",
    "\n",
    "# If desired, we could proceed to store `result` in a standardized HDF5 or JSON format.\n",
    "save_dict_to_hdf5(result, \"data/LohnasKahana2014.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fc74e6-624b-4df3-8160-0d6206c5aef0",
   "metadata": {},
   "source": [
    "We also add automated tests to verify our final `result` structure meets the following conditions:\n",
    "\n",
    " 1. **All entries** are 2D.\n",
    " 2. **Subject**, **session**, **listLength**, and **list_type** each has exactly one column.\n",
    " 3. All **other entries** have the same number of columns (40).\n",
    " 4. The **minimum value** for all entries is at least 0.\n",
    " 5. **Zeros** in `rec_itemids`, `recalls`, and `irt` occupy **the same** indices (if `irt` is the same shape)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab0c4555-f027-40b3-ae59-698eade2becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. All entries are 2D\n",
    "for key, val in result.items():\n",
    "    assert val.ndim == 2, f\"{key} must be 2D. Got shape={val.shape}.\"\n",
    "\n",
    "# 2. subject, session, listLength, and list_type must have exactly one column\n",
    "single_col_keys = [\"subject\", \"session\", \"listLength\", \"list_type\"]\n",
    "for k in single_col_keys:\n",
    "    if k in result:\n",
    "        assert result[k].shape[1] == 1, f\"{k} must have shape (n_trials, 1). Got {result[k].shape}.\"\n",
    "\n",
    "# 3. All other entries have the same number of columns (40)\n",
    "column_40_keys = [\n",
    "    \"pres_itemnos\", \"recalls\", \"pres_itemids\", \"rec_itemids\"\n",
    "]\n",
    "# If irt is also supposed to have 40 columns, include it:\n",
    "# column_40_keys.append(\"irt\")\n",
    "\n",
    "for k in column_40_keys:\n",
    "    if k in result:\n",
    "        assert result[k].shape[1] == 40, f\"{k} must have 40 columns. Got {result[k].shape}.\"\n",
    "\n",
    "# 4. Minimum value for all entries is at least 0\n",
    "for key, val in result.items():\n",
    "    min_val = val.min()\n",
    "    assert min_val >= 0, f\"{key} has negative values (min={min_val}).\"\n",
    "\n",
    "# 5. 0 values in rec_itemids, recalls, and irt occupy the same indices\n",
    "#    (only if your `irt` array has the same shape as recalls).\n",
    "if \"rec_itemids\" in result and \"recalls\" in result:\n",
    "    rec_itemids_zeros = (result[\"rec_itemids\"] == 0)\n",
    "    recalls_zeros     = (result[\"recalls\"]     == 0)\n",
    "\n",
    "    # If irt is present and the same shape, compare it too\n",
    "    if \"irt\" in result and result[\"irt\"].shape == result[\"recalls\"].shape:\n",
    "        irt_zeros = (result[\"irt\"] == 0)\n",
    "        # All must match\n",
    "        assert (\n",
    "            (rec_itemids_zeros == recalls_zeros).all() and \n",
    "            (recalls_zeros == irt_zeros).all()\n",
    "        ), \"Mismatch in zero indices among rec_itemids, recalls, and irt.\"\n",
    "    else:\n",
    "        # If no irt or shape mismatch, just compare rec_itemids and recalls\n",
    "        assert (rec_itemids_zeros == recalls_zeros).all(), \\\n",
    "            \"Mismatch in zero indices between rec_itemids and recalls.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
