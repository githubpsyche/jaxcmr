{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import config\n",
    "\n",
    "config.DISABLE_JIT = True\n",
    "\n",
    "import numpy as np\n",
    "from psifr.stats import percentile_rank\n",
    "from compmempy.helpers.transforming_arrays import njit_apply_along_axis\n",
    "from compmempy.helpers.handling_data import item_to_study_positions, apply_by_subject\n",
    "from compmempy.helpers.loading_data import to_numba_typed_dict\n",
    "from jaxcmr_research.helpers.hdf5 import generate_trial_mask, load_data\n",
    "\n",
    "from compmempy.analyses.repcrp import repcrp\n",
    "\n",
    "\n",
    "def score_rep_crp(\n",
    "    data: dict[str, np.ndarray],\n",
    "    trial_mask: np.ndarray,\n",
    "    max_repetitions: int = 3,\n",
    "    min_lag: int = 4,\n",
    "):\n",
    "    subject_values = apply_by_subject(\n",
    "        data,\n",
    "        trial_mask,\n",
    "        repcrp,\n",
    "        max_repetitions,\n",
    "        min_lag,\n",
    "    )\n",
    "\n",
    "    list_length = np.max(data[\"listLength\"])\n",
    "    # return (np.array(subject_values)[:, :, list_length] + np.array(subject_values)[:, :, list_length+1] + np.array(subject_values)[:, :, list_length+2]) / 3\n",
    "    return np.array(subject_values)[:, :, list_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"LohnasKahana2014\"\n",
    "data_path = \"data/LohnasKahana2014.h5\"\n",
    "data_query = \"data['list_type'] == 4\"\n",
    "\n",
    "data = to_numba_typed_dict(\n",
    "    {key: np.array(value) for key, value in load_data(data_path).items()}\n",
    ")\n",
    "trial_mask = generate_trial_mask(data, data_query)\n",
    "\n",
    "max_repetitions = 2\n",
    "min_lag = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26315789, 0.15      ],\n",
       "       [0.16666667, 0.11111111],\n",
       "       [0.15      , 0.        ],\n",
       "       [0.18181818, 0.        ],\n",
       "       [0.11111111, 0.05263158],\n",
       "       [0.28571429, 0.16666667],\n",
       "       [0.        , 0.22222222],\n",
       "       [0.16666667, 0.13043478],\n",
       "       [0.25      , 0.        ],\n",
       "       [0.19047619, 0.15384615],\n",
       "       [0.46875   , 0.03125   ],\n",
       "       [0.22222222, 0.11111111],\n",
       "       [0.05263158, 0.04347826],\n",
       "       [0.23809524, 0.13043478],\n",
       "       [0.14285714, 0.05      ],\n",
       "       [0.41176471, 0.        ],\n",
       "       [0.17391304, 0.04545455],\n",
       "       [0.16666667, 0.14285714],\n",
       "       [0.        , 0.        ],\n",
       "       [0.2       , 0.04761905],\n",
       "       [0.        , 0.        ],\n",
       "       [0.19047619, 0.11764706],\n",
       "       [0.        , 0.05263158],\n",
       "       [0.33333333, 0.        ],\n",
       "       [0.        , 0.08333333],\n",
       "       [0.11111111, 0.        ],\n",
       "       [0.35      , 0.09090909],\n",
       "       [0.        , 0.09090909],\n",
       "       [0.125     , 0.06666667],\n",
       "       [0.17647059, 0.05      ],\n",
       "       [0.07692308, 0.        ],\n",
       "       [0.31818182, 0.22222222],\n",
       "       [0.10526316, 0.23529412],\n",
       "       [0.14285714, 0.08333333],\n",
       "       [0.22222222, 0.28571429]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_values = score_rep_crp(data, trial_mask, max_repetitions, min_lag)\n",
    "\n",
    "subject_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = subject_values\n",
    "data1, data2 = difference[:, 0], difference[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 3.7039144020051795\n",
      "One-tailed P-value: 0.00037491219571755445\n",
      "There is a statistically significant difference between the two paired samples at the 5% significance level.\n",
      "Mean First Sample: 0.17126714961640352\n",
      "Mean Second Sample: 0.08479366241223729\n",
      "Standard Error First Sample: 0.01979637485332103\n",
      "Standard Error Second Sample: 0.01289293099460334\n",
      "Mean Difference: 0.08647348720416619\n",
      "Standard Error Difference: 0.023010574825834136\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "t_statistic, p_value = ttest_rel(data1, data2, alternative=\"greater\")\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"One-tailed P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\n",
    "        \"There is a statistically significant difference between the two paired samples at the 5% significance level.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"There is no statistically significant difference between the two paired samples at the 5% significance level.\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"Mean First Sample: {np.mean(data1)}\")\n",
    "print(f\"Mean Second Sample: {np.mean(data2)}\")\n",
    "print(f\"Standard Error First Sample: {np.std(data1) / np.sqrt(len(data1))}\")\n",
    "print(f\"Standard Error Second Sample: {np.std(data2) / np.sqrt(len(data2))}\")\n",
    "print(f\"Mean Difference: {np.mean(data1 - data2)}\")\n",
    "print(f\"Standard Error Difference: {np.std(data1 - data2) / np.sqrt(len(data1))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:00, 1373.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.21573698, 0.19689462],\n",
       "       [0.09202013, 0.16529492],\n",
       "       [0.1202211 , 0.15475649],\n",
       "       [0.18223235, 0.06800446],\n",
       "       [0.08936826, 0.13654189],\n",
       "       [0.15721531, 0.15931907],\n",
       "       [0.17507418, 0.17907445],\n",
       "       [0.09120699, 0.08237644],\n",
       "       [0.15384615, 0.31143399],\n",
       "       [0.1085297 , 0.07787934],\n",
       "       [0.41376812, 0.23415265],\n",
       "       [0.09529652, 0.11083229],\n",
       "       [0.10440395, 0.12709832],\n",
       "       [0.32299084, 0.22008253],\n",
       "       [0.05882353, 0.03554377],\n",
       "       [0.21194503, 0.25513196],\n",
       "       [0.20602767, 0.10147601],\n",
       "       [0.2166157 , 0.14165103],\n",
       "       [0.06846673, 0.06994329],\n",
       "       [0.10475651, 0.08972353],\n",
       "       [0.09467456, 0.17736185],\n",
       "       [0.13864307, 0.1046832 ],\n",
       "       [0.06886228, 0.05563798],\n",
       "       [0.1671415 , 0.18703108],\n",
       "       [0.10068493, 0.09970015],\n",
       "       [0.16198126, 0.02203182],\n",
       "       [0.22889007, 0.18959811],\n",
       "       [0.13362069, 0.06505421],\n",
       "       [0.11565696, 0.15073815],\n",
       "       [0.1191446 , 0.11994003],\n",
       "       [0.03322034, 0.06649111],\n",
       "       [0.27617044, 0.18212912],\n",
       "       [0.09302326, 0.16834401],\n",
       "       [0.05941213, 0.10121212],\n",
       "       [0.33584906, 0.18708972]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jaxcmr_research.helpers.repetition import control_dataset\n",
    "\n",
    "ctrl_data = control_dataset(\n",
    "    to_numba_typed_dict({key: np.array(value) for key, value in data.items()}),\n",
    "    \"data['list_type'] == 4\",\n",
    "    \"data['list_type'] == 1\",\n",
    "    100,\n",
    ")\n",
    "\n",
    "ctrl_subject_values = score_rep_crp(\n",
    "    ctrl_data,\n",
    "    generate_trial_mask(ctrl_data, \"data['subject'] != -1\"),\n",
    "    max_repetitions,\n",
    "    min_lag,\n",
    ")\n",
    "\n",
    "ctrl_subject_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = subject_values - ctrl_subject_values\n",
    "data1, data2 = difference[:, 0], difference[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 2.8377861275499554\n",
      "One-tailed P-value: 0.0038033671943909953\n",
      "There is a statistically significant difference between the two paired samples at the 5% significance level.\n",
      "Mean First Sample: 0.019395124297992707\n",
      "Mean Second Sample: -0.05218501489244075\n",
      "Standard Error First Sample: 0.014968251854968036\n",
      "Standard Error Second Sample: 0.015492476579109554\n",
      "Mean Difference: 0.07158013919043346\n",
      "Standard Error Difference: 0.024860983971650943\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "t_statistic, p_value = ttest_rel(data1, data2, alternative=\"greater\")\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"One-tailed P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\n",
    "        \"There is a statistically significant difference between the two paired samples at the 5% significance level.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"There is no statistically significant difference between the two paired samples at the 5% significance level.\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"Mean First Sample: {np.mean(data1)}\")\n",
    "print(f\"Mean Second Sample: {np.mean(data2)}\")\n",
    "print(f\"Standard Error First Sample: {np.std(data1) / np.sqrt(len(data1))}\")\n",
    "print(f\"Standard Error Second Sample: {np.std(data2) / np.sqrt(len(data2))}\")\n",
    "print(f\"Mean Difference: {np.mean(data1 - data2)}\")\n",
    "print(f\"Standard Error Difference: {np.std(data1 - data2) / np.sqrt(len(data1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base CMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| | | Cond4LohnasKahana2014 BaseCMR Model Fitting |\n",
       "|---|---|---|\n",
       "| fitness | mean | 470.79 +/- 50.44 |\n",
       "| | std | 144.72 |\n",
       "| mfc trace sensitivity | mean | 1.00 +/- 0.00 |\n",
       "| | std | 0.00 |\n",
       "| start drift rate | mean | 0.45 +/- 0.12 |\n",
       "| | std | 0.35 |\n",
       "| mcf trace sensitivity | mean | 1.00 +/- 0.00 |\n",
       "| | std | 0.00 |\n",
       "| recall drift rate | mean | 0.89 +/- 0.06 |\n",
       "| | std | 0.17 |\n",
       "| primacy decay | mean | 13.34 +/- 9.57 |\n",
       "| | std | 27.46 |\n",
       "| semantic choice sensitivity | mean | 0.00 +/- 0.00 |\n",
       "| | std | 0.00 |\n",
       "| encoding drift rate | mean | 0.73 +/- 0.06 |\n",
       "| | std | 0.16 |\n",
       "| learning rate | mean | 0.39 +/- 0.07 |\n",
       "| | std | 0.21 |\n",
       "| item support | mean | 8.18 +/- 2.96 |\n",
       "| | std | 8.49 |\n",
       "| stop probability scale | mean | 0.02 +/- 0.01 |\n",
       "| | std | 0.03 |\n",
       "| mfc choice sensitivity | mean | 1.00 +/- 0.00 |\n",
       "| | std | 0.00 |\n",
       "| primacy scale | mean | 18.93 +/- 9.81 |\n",
       "| | std | 28.15 |\n",
       "| semantic scale | mean | 0.00 +/- 0.00 |\n",
       "| | std | 0.00 |\n",
       "| choice sensitivity | mean | 35.07 +/- 12.97 |\n",
       "| | std | 37.22 |\n",
       "| stop probability growth | mean | 0.24 +/- 0.04 |\n",
       "| | std | 0.11 |\n",
       "| shared support | mean | 7.86 +/- 5.05 |\n",
       "| | std | 14.49 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jaxcmr_research.helpers.hdf5 import simulate_h5_from_h5\n",
    "from jax import random\n",
    "from jaxcmr_research.helpers.hdf5 import generate_trial_mask, load_data\n",
    "from jaxcmr_research.helpers.misc import summarize_parameters, import_from_string\n",
    "import numpy as np\n",
    "from jaxcmr_research.helpers.array import compute_similarity_matrix\n",
    "from jax import numpy as jnp\n",
    "import json\n",
    "from IPython.display import Markdown  # type: ignore\n",
    "\n",
    "data_name = \"Cond34LohnasKahana2014\"\n",
    "data_path = \"data/LohnasKahana2014.h5\"\n",
    "data_query = \"data['list_type'] >= 3\"\n",
    "connection_path = \"data/peers-all-mpnet-base-v2.npy\"\n",
    "experiment_count = 1\n",
    "seed = 0\n",
    "fit_result_path = (\n",
    "    \"notebooks/Model_Fitting/Cond4LohnasKahana2014_BaseCMR_Model_Fitting.json\"\n",
    ")\n",
    "\n",
    "\n",
    "data = load_data(data_path)\n",
    "trial_mask = generate_trial_mask(data, data_query)\n",
    "embeddings = np.load(connection_path)\n",
    "connections = compute_similarity_matrix(embeddings)  # unused here\n",
    "model_factory_path = \"jaxcmr_research.cmr.BaseCMRFactory\"\n",
    "model_factory = import_from_string(model_factory_path)\n",
    "with open(fit_result_path, \"r\") as f:\n",
    "    results = json.load(f)\n",
    "    if \"subject\" not in results[\"fits\"]:\n",
    "        results[\"fits\"][\"subject\"] = results[\"subject\"]\n",
    "\n",
    "\n",
    "Markdown(summarize_parameters([results], None, include_std=True, include_ci=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.PRNGKey(seed)\n",
    "rng, rng_iter = random.split(rng)\n",
    "sim = simulate_h5_from_h5(\n",
    "    model_factory=model_factory,\n",
    "    dataset=data,\n",
    "    connections=connections,\n",
    "    parameters={key: jnp.array(val) for key, val in results[\"fits\"].items()},\n",
    "    trial_mask=generate_trial_mask(data, 'data[\"subject\"] != -1'),\n",
    "    experiment_count=experiment_count,\n",
    "    rng=rng_iter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordangunn/compmempy/compmempy/analyses/repcrp.py:104: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.actual_lag_transitions / self.possible_lag_transitions\n",
      "35it [00:00, 1379.58it/s]\n",
      "/Users/jordangunn/compmempy/compmempy/analyses/repcrp.py:104: RuntimeWarning: divide by zero encountered in divide\n",
      "  return self.actual_lag_transitions / self.possible_lag_transitions\n"
     ]
    }
   ],
   "source": [
    "subject_values = score_rep_crp(\n",
    "    sim, generate_trial_mask(sim, \"data['list_type'] == 4\"), max_repetitions, min_lag\n",
    ")\n",
    "\n",
    "ctrl_sim = control_dataset(\n",
    "    to_numba_typed_dict({key: np.array(val) for key, val in sim.items()}),\n",
    "    \"data['list_type'] == 4\",\n",
    "    \"data['list_type'] == 1\",\n",
    "    100,\n",
    ")\n",
    "\n",
    "ctrl_subject_values = score_rep_crp(\n",
    "    ctrl_sim,\n",
    "    generate_trial_mask(ctrl_sim, \"data['subject'] != -1\"),\n",
    "    max_repetitions,\n",
    "    min_lag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = subject_values - ctrl_subject_values\n",
    "data1, data2 = difference[:, 0], difference[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 1.0720050865921524\n",
      "One-tailed P-value: 0.14563413572570685\n",
      "There is no statistically significant difference between the two paired samples at the 5% significance level.\n",
      "Mean First Sample: 0.04147011354341045\n",
      "Mean Second Sample: 0.014878364318236576\n",
      "Standard Error First Sample: 0.01500577943596517\n",
      "Standard Error Second Sample: 0.015600549327887013\n",
      "Mean Difference: 0.02659174922517387\n",
      "Standard Error Difference: 0.024448684532896305\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "t_statistic, p_value = ttest_rel(data1, data2, alternative=\"greater\")\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"One-tailed P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\n",
    "        \"There is a statistically significant difference between the two paired samples at the 5% significance level.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"There is no statistically significant difference between the two paired samples at the 5% significance level.\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"Mean First Sample: {np.mean(data1)}\")\n",
    "print(f\"Mean Second Sample: {np.mean(data2)}\")\n",
    "print(f\"Standard Error First Sample: {np.std(data1) / np.sqrt(len(data1))}\")\n",
    "print(f\"Standard Error Second Sample: {np.std(data2) / np.sqrt(len(data2))}\")\n",
    "print(f\"Mean Difference: {np.mean(data1 - data2)}\")\n",
    "print(f\"Standard Error Difference: {np.std(data1 - data2) / np.sqrt(len(data1))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxcmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
