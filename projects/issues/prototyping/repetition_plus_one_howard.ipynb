{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import config\n",
    "\n",
    "config.DISABLE_JIT = True\n",
    "\n",
    "import numpy as np\n",
    "from psifr.stats import percentile_rank\n",
    "from compmempy.helpers.transforming_arrays import njit_apply_along_axis\n",
    "from compmempy.helpers.handling_data import item_to_study_positions, apply_by_subject\n",
    "from compmempy.helpers.loading_data import to_numba_typed_dict\n",
    "from jaxcmr_research.helpers.hdf5 import generate_trial_mask, load_data\n",
    "\n",
    "from compmempy.analyses.repcrp import repcrp\n",
    "\n",
    "\n",
    "def score_rep_crp(\n",
    "    data: dict[str, np.ndarray],\n",
    "    trial_mask: np.ndarray,\n",
    "    max_repetitions: int = 3,\n",
    "    min_lag: int = 4,\n",
    "):\n",
    "    subject_values = apply_by_subject(\n",
    "        data,\n",
    "        trial_mask,\n",
    "        repcrp,\n",
    "        max_repetitions,\n",
    "        min_lag,\n",
    "    )\n",
    "\n",
    "    list_length = np.max(data[\"listLength\"])\n",
    "    # return (np.array(subject_values)[:, :, list_length] + np.array(subject_values)[:, :, list_length+1] + np.array(subject_values)[:, :, list_length+2]) / 3\n",
    "    return np.array(subject_values)[:, :, list_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"HowardKahana2005\"\n",
    "data_path = \"data/HowardKahana2005.h5\"\n",
    "data_query = \"data['condition'] > 0\"\n",
    "\n",
    "data = to_numba_typed_dict(\n",
    "    {key: np.array(value) for key, value in load_data(data_path).items()}\n",
    ")\n",
    "trial_mask = generate_trial_mask(data, data_query)\n",
    "\n",
    "max_repetitions = 3\n",
    "min_lag = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15384615, 0.1       , 0.16216216],\n",
       "       [0.09615385, 0.05660377, 0.08510638],\n",
       "       [0.09375   , 0.12307692, 0.05172414],\n",
       "       [0.17460317, 0.17647059, 0.14925373],\n",
       "       [0.45833333, 0.29464286, 0.13114754],\n",
       "       [0.16483516, 0.14285714, 0.09677419],\n",
       "       [0.07692308, 0.14634146, 0.05882353],\n",
       "       [0.06521739, 0.09090909, 0.20512821],\n",
       "       [0.06153846, 0.12698413, 0.18333333],\n",
       "       [0.07142857, 0.16      , 0.08      ],\n",
       "       [0.12      , 0.15686275, 0.02777778],\n",
       "       [0.11290323, 0.12121212, 0.10294118],\n",
       "       [0.11764706, 0.09433962, 0.0625    ],\n",
       "       [0.08333333, 0.13043478, 0.13636364],\n",
       "       [0.15730337, 0.11827957, 0.13580247],\n",
       "       [0.05      , 0.01754386, 0.16981132],\n",
       "       [0.10714286, 0.03846154, 0.10344828],\n",
       "       [0.06521739, 0.16326531, 0.06666667],\n",
       "       [0.10169492, 0.12068966, 0.09259259],\n",
       "       [0.        , 0.0952381 , 0.10526316],\n",
       "       [0.27272727, 0.15      , 0.13636364],\n",
       "       [0.15625   , 0.07407407, 0.03703704],\n",
       "       [0.09090909, 0.12121212, 0.0625    ],\n",
       "       [0.08888889, 0.07142857, 0.04651163],\n",
       "       [0.08064516, 0.12698413, 0.08333333],\n",
       "       [0.10714286, 0.10714286, 0.03333333],\n",
       "       [0.06329114, 0.07692308, 0.05797101],\n",
       "       [0.12068966, 0.06779661, 0.15686275],\n",
       "       [0.15625   , 0.11111111, 0.13888889],\n",
       "       [0.14285714, 0.08823529, 0.03030303],\n",
       "       [0.06666667, 0.02083333, 0.06666667],\n",
       "       [0.17647059, 0.0877193 , 0.06557377],\n",
       "       [0.11428571, 0.13888889, 0.        ],\n",
       "       [0.15714286, 0.12162162, 0.16216216],\n",
       "       [0.06818182, 0.05660377, 0.0754717 ],\n",
       "       [0.12244898, 0.08928571, 0.09615385],\n",
       "       [0.11538462, 0.08860759, 0.07792208],\n",
       "       [0.10416667, 0.07692308, 0.04      ],\n",
       "       [0.08108108, 0.11764706, 0.13333333],\n",
       "       [0.02941176, 0.02941176, 0.07692308],\n",
       "       [0.09803922, 0.02173913, 0.        ],\n",
       "       [0.0862069 , 0.13559322, 0.13559322],\n",
       "       [0.12162162, 0.09589041, 0.16216216],\n",
       "       [0.11764706, 0.16981132, 0.14583333],\n",
       "       [0.14893617, 0.10204082, 0.13978495],\n",
       "       [0.06060606, 0.        , 0.07142857],\n",
       "       [0.11666667, 0.08474576, 0.10526316],\n",
       "       [0.14814815, 0.07692308, 0.03846154],\n",
       "       [0.09090909, 0.02380952, 0.11111111],\n",
       "       [0.15254237, 0.06896552, 0.07017544],\n",
       "       [0.17391304, 0.04347826, 0.        ],\n",
       "       [0.17567568, 0.10144928, 0.10447761],\n",
       "       [0.09677419, 0.04918033, 0.13114754],\n",
       "       [0.06976744, 0.125     , 0.09756098],\n",
       "       [0.05084746, 0.11111111, 0.06122449],\n",
       "       [0.08510638, 0.06122449, 0.07142857],\n",
       "       [0.17460317, 0.11290323, 0.11666667],\n",
       "       [0.15384615, 0.0754717 , 0.02      ],\n",
       "       [0.10909091, 0.06779661, 0.13461538],\n",
       "       [0.22857143, 0.1       , 0.06060606],\n",
       "       [0.10909091, 0.06779661, 0.13461538],\n",
       "       [0.03030303, 0.07462687, 0.07272727],\n",
       "       [0.10447761, 0.10294118, 0.07407407],\n",
       "       [0.15909091, 0.11904762, 0.10714286],\n",
       "       [0.15294118, 0.08333333, 0.06944444],\n",
       "       [0.13414634, 0.07894737, 0.07575758]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_values = score_rep_crp(data, trial_mask, max_repetitions, min_lag)\n",
    "\n",
    "subject_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = subject_values\n",
    "data1, data2 = difference[:, 0], difference[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 2.9086583323134523\n",
      "One-tailed P-value: 0.0024814113527138544\n",
      "There is a statistically significant difference between the two paired samples at the 5% significance level.\n",
      "Mean First Sample: 0.11812624891416693\n",
      "Mean Second Sample: 0.09773469670491197\n",
      "Standard Error First Sample: 0.007758963650018588\n",
      "Standard Error Second Sample: 0.005670229294661995\n",
      "Mean Difference: 0.02039155220925494\n",
      "Standard Error Difference: 0.006957324927386909\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "t_statistic, p_value = ttest_rel(data1, data2, alternative=\"greater\")\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"One-tailed P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\n",
    "        \"There is a statistically significant difference between the two paired samples at the 5% significance level.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"There is no statistically significant difference between the two paired samples at the 5% significance level.\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"Mean First Sample: {np.mean(data1)}\")\n",
    "print(f\"Mean Second Sample: {np.mean(data2)}\")\n",
    "print(f\"Standard Error First Sample: {np.std(data1) / np.sqrt(len(data1))}\")\n",
    "print(f\"Standard Error Second Sample: {np.std(data2) / np.sqrt(len(data2))}\")\n",
    "print(f\"Mean Difference: {np.mean(data1 - data2)}\")\n",
    "print(f\"Standard Error Difference: {np.std(data1 - data2) / np.sqrt(len(data1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base CMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| | | HowardKahana2005 BaseCMR Model Fitting |\n",
       "|---|---|---|\n",
       "| fitness | mean | 323.03 +/- 23.84 |\n",
       "| | std | 96.23 |\n",
       "| mfc choice sensitivity | mean | 1.00 +/- 0.00 |\n",
       "| | std | 0.00 |\n",
       "| start drift rate | mean | 0.47 +/- 0.08 |\n",
       "| | std | 0.33 |\n",
       "| semantic scale | mean | 0.00 +/- 0.00 |\n",
       "| | std | 0.00 |\n",
       "| primacy scale | mean | 12.77 +/- 5.16 |\n",
       "| | std | 20.83 |\n",
       "| choice sensitivity | mean | 51.03 +/- 7.74 |\n",
       "| | std | 31.26 |\n",
       "| semantic choice sensitivity | mean | 0.00 +/- 0.00 |\n",
       "| | std | 0.00 |\n",
       "| stop probability growth | mean | 0.32 +/- 0.03 |\n",
       "| | std | 0.11 |\n",
       "| item support | mean | 30.95 +/- 6.28 |\n",
       "| | std | 25.34 |\n",
       "| mcf trace sensitivity | mean | 1.00 +/- 0.00 |\n",
       "| | std | 0.00 |\n",
       "| shared support | mean | 23.77 +/- 4.86 |\n",
       "| | std | 19.63 |\n",
       "| stop probability scale | mean | 0.02 +/- 0.01 |\n",
       "| | std | 0.02 |\n",
       "| mfc trace sensitivity | mean | 1.00 +/- 0.00 |\n",
       "| | std | 0.00 |\n",
       "| learning rate | mean | 0.23 +/- 0.08 |\n",
       "| | std | 0.31 |\n",
       "| encoding drift rate | mean | 0.61 +/- 0.06 |\n",
       "| | std | 0.26 |\n",
       "| primacy decay | mean | 31.36 +/- 7.68 |\n",
       "| | std | 30.99 |\n",
       "| recall drift rate | mean | 0.84 +/- 0.05 |\n",
       "| | std | 0.19 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jaxcmr_research.helpers.hdf5 import simulate_h5_from_h5\n",
    "from jax import random\n",
    "from jaxcmr_research.helpers.hdf5 import generate_trial_mask, load_data\n",
    "from jaxcmr_research.helpers.misc import summarize_parameters, import_from_string\n",
    "import numpy as np\n",
    "from jaxcmr_research.helpers.array import compute_similarity_matrix\n",
    "from jax import numpy as jnp\n",
    "import json\n",
    "from IPython.display import Markdown  # type: ignore\n",
    "\n",
    "data_name = \"HowardKahana2005\"\n",
    "data_path = \"data/HowardKahana2005.h5\"\n",
    "data_query = \"data['condition'] > 0\"\n",
    "connection_path = \"data/peers-all-mpnet-base-v2.npy\"\n",
    "experiment_count = 1\n",
    "seed = 0\n",
    "fit_result_path = (\n",
    "    \"notebooks/Model_Fitting//HowardKahana2005_BaseCMR_Model_Fitting.json\"\n",
    ")\n",
    "\n",
    "\n",
    "data = load_data(data_path)\n",
    "trial_mask = generate_trial_mask(data, data_query)\n",
    "embeddings = np.load(connection_path)\n",
    "connections = compute_similarity_matrix(embeddings)  # unused here\n",
    "model_factory_path = \"jaxcmr_research.cmr.BaseCMRFactory\"\n",
    "model_factory = import_from_string(model_factory_path)\n",
    "with open(fit_result_path, \"r\") as f:\n",
    "    results = json.load(f)\n",
    "    if \"subject\" not in results[\"fits\"]:\n",
    "        results[\"fits\"][\"subject\"] = results[\"subject\"]\n",
    "\n",
    "\n",
    "Markdown(summarize_parameters([results], None, include_std=True, include_ci=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.PRNGKey(seed)\n",
    "rng, rng_iter = random.split(rng)\n",
    "sim = simulate_h5_from_h5(\n",
    "    model_factory=model_factory,\n",
    "    dataset=data,\n",
    "    connections=connections,\n",
    "    parameters={key: jnp.array(val) for key, val in results[\"fits\"].items()},\n",
    "    trial_mask=generate_trial_mask(data, 'data[\"subject\"] != -1'),\n",
    "    experiment_count=experiment_count,\n",
    "    rng=rng_iter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordangunn/compmempy/compmempy/analyses/repcrp.py:104: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.actual_lag_transitions / self.possible_lag_transitions\n"
     ]
    }
   ],
   "source": [
    "subject_values = score_rep_crp(\n",
    "    sim, generate_trial_mask(sim, \"data['condition'] > 0\"), max_repetitions, min_lag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = subject_values\n",
    "data1, data2 = difference[:, 0], difference[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 0.9331725226465978\n",
      "One-tailed P-value: 0.17709222753926546\n",
      "There is no statistically significant difference between the two paired samples at the 5% significance level.\n",
      "Mean First Sample: 0.09806671341852317\n",
      "Mean Second Sample: 0.09234026106294912\n",
      "Standard Error First Sample: 0.006925938336803495\n",
      "Standard Error Second Sample: 0.00690530373562172\n",
      "Mean Difference: 0.00572645235557405\n",
      "Standard Error Difference: 0.006089875579766138\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "t_statistic, p_value = ttest_rel(data1, data2, alternative=\"greater\")\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"One-tailed P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\n",
    "        \"There is a statistically significant difference between the two paired samples at the 5% significance level.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"There is no statistically significant difference between the two paired samples at the 5% significance level.\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"Mean First Sample: {np.mean(data1)}\")\n",
    "print(f\"Mean Second Sample: {np.mean(data2)}\")\n",
    "print(f\"Standard Error First Sample: {np.std(data1) / np.sqrt(len(data1))}\")\n",
    "print(f\"Standard Error Second Sample: {np.std(data2) / np.sqrt(len(data2))}\")\n",
    "print(f\"Mean Difference: {np.mean(data1 - data2)}\")\n",
    "print(f\"Standard Error Difference: {np.std(data1 - data2) / np.sqrt(len(data1))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxcmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
