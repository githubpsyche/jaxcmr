https://mark-hurlstone.github.io/HHB.14.PB.pdf this review of models of serial recall from hurlstone helps categorize CMR as a serial recall model.

-   Competitive queuing models treat sequence recall as a two-stage process.
    First, items are activated in parallel based on an ordering mechanisms, with relative activation strengths coding item priority.
    Second, a competitive choice process across items based on their representations.
    CMR does this, and can be distinguished from associative chaining models that instead directly associated studied items with their successors.
    InstanceCMR can be intepreted as posing an alternative hypothesis that competing representations are distinct memory traces rather than items.

<!-- -->

-   Position marking models associate items with an independent and varying contextual representation of their position. Variants are a lot like CMR, but the key word in this definition that regular CMR doesn't meet is "independent", as CMR's contextual code is not item-independent. Our paper can be interpreted as building a case for an item-independent representation.
-   Primacy gradient models -- well you can probably guess. CMR since Sederberg (2008) ? integrates a explicit primacy gradient into its specification and that seems to be true for most position-marking serial recall models too. But in an alternative approach, a single context cue is sufficient to retrieve the primacy gradient of activations; after this, ordered recall proceeds without the need to reinstate any additional context cues. I find it a pretty interested idea to consider but differences between PFR curves and serial position curves seem likely to discredit a straightforward implementation of the approach for CMR.
-   Pretty much all CQ models include response suppression, but positional coding models apparently need it less than pure primacy gradient models because it includes mechanisms that avoid perserverating the same response over and over again. This observation helps clarify why CMR and CRU work alright even without an explicit response suppression mechanism.
-   Cumulative matching. This one seems to address a familiar pattern in multi-trial experiments. In an phenomenon called the Hebb repetition effect, repeating the same sequence every few trials boosts memory for the repeated sequence over novel filler sequences. This reads to me as a converse of the item-based intrusion effects modeled in Lynn's paper, and is thus really important for us who have embraced an item-based account of contextual evolution in part on the basis of its ability to help address inter-list effects. It seems that serial recall modelers interpret this as the task of "recognizing" whether an incoming sequence is a novel sequence or one that has been encountered previously. Cumulative matching models incrementally match incoming sequences to the representations of previously presented sequences to establish whether it's familiar or not. Regular CMR does something similar already by allowing context to reflect a history of past encoding events rather than just the most recently encoded item; it allows that subsequences in past lists can be increasingly strongly cued the more the current sequence matches those past subsequences. Is interesting though to consider that this may be possible in just a positional coding model.
-   Output interference models implement the notion that recall of an item can interfere with representations or accessibility of items yet to be recalled. This seems necessarily true in CMR, but model models volunteer explicit mechanisms.
-   Locus of similarity effects. There's apparently a lot of debate on whether similarity effects should be explained in terms of retrieval or if similarity also affects encoding. The version of CMR favored in Morton & Polyn (2016) seems to favor a pure retrieval-focused account but DCMR seems to emphasize both encoding and retrieval processes. If positional CMR really does turn out to be better than an exclusively item-dependent CMR, it makes interpreting results around DCMR kind of tricky, though not impossible. If story recall proceeds like serial recall, the evidence in this space could be really helpful.

Evidence for CQ models:

-   Greater incidence of transposition than item errors

-   Locality constraint underlying tanspositions

-   Also: effects of primacy and recency of the serial position curve

-   Also: sequence length effect

-   "All CQ models predict that the most common errors will be movements and exchanges between items" because "the strongest competitors to the target item at each recal position will be items from adjacent serial positions"

Evidence for position-marking models unique to position-marking models:

-   Transposition errors between temporal groups that preserve their positions within groups.
    For example, if a nine-item sequence is organized into three groups of three, interpositions are indicated by an increase in the probaiblity of +/- 3 and +/-6 transpositions.
    Position-marking models explain by postulating that positional information in grouped seuqences is represented on at least two dimensions, with one representing position in sequence and another representing position within groups.

-   Patterns of positional intrusions – protrusions where an item from a previous list “protrudes” into the current recall, appearing in the same output position it occupied before.
    This doesn't seem predicted by CMR the way subsequence recall does.
    Errors are said to manifest because items occupying the same seuqence position on different trials will possess similar within-sequence positional codes.