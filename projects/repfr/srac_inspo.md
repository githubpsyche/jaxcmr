https://chatgpt.com/share/67df1db4-5b98-8012-8329-229d0dcb56c6

Serial Position Curves in Serial Recall Tasks

When examining serial recall (where participants must recall list items in the original order), researchers typically plot serial position curves showing recall accuracy at each list position. In contrast to free recall (where order is irrelevant), serial recall scoring usually requires an item to be recalled in its correct position to count as correct. Below we outline standard practices for computing accuracy by serial position in serial recall tasks, including how to handle special cases like repeated items, what counts as an “accurate” recall (strict vs. lenient criteria), and how to treat order errors (transpositions). We also discuss best practices for visualizing serial recall data – such as plotting accuracy by input position and analyzing transposition gradients – and highlight key differences from free recall curves. Throughout, we reference empirical findings and conventions from the literature to guide how one might evaluate a memory model against human data.

Scoring Accuracy by Serial Position in Serial Recall

Strict item-in-position scoring is the most common way to compute recall accuracy in serial recall tasks ￼. Under this strict criterion, a response is scored correct only if the correct item for that serial position is produced in that exact position. In other words, each list position is treated as a slot that must be filled with the originally presented item – if that item is recalled in the correct position, it contributes to accuracy for that position (typically tallied as proportion of trials recalled correctly at that position). Any deviation (wrong item or item from a different position) is counted as an error for that position. This strict positional scoring aligns with instructions to recall items in order (often “verbatim” recall of the sequence). It captures both item memory and order memory simultaneously, as an item is only “correct” if it is not only recalled but also placed in its original slot.

Under strict scoring, transposition errors – recalling a list item in the wrong serial position – do not count as correct for either of the involved positions. For example, if the item that was presented 3rd is mistakenly recalled in the 4th output position, position 4 would be scored incorrect (since the item belongs in position 3, not 4), and position 3 would also be scored incorrect (its correct item wasn’t recalled in place). In formal terms, “a transposition error [occurs] when an item from the study sequence is recalled in an incorrect position,” whereas an “item error” refers to recalling an item that was never on the list (or otherwise completely wrong item) ￼. Thus, strict scoring only credits exact matches of item and position, and any displacement of an item from its target position results in those positions being marked wrong. This method is straightforward and has been the default in many classic immediate serial recall studies ￼.

Lenient scoring approaches. Researchers have noted that strict scoring can under-count performance in cases where participants recalled the correct items but some were out of order. In longer lists or unconstrained oral recall, a participant might skip an item and continue recalling subsequent items in the correct sequence, which strict scoring would count as a string of failures for all remaining positions ￼. To address this, alternative scoring methods allow some leniency regarding order. One such method is relative order scoring, where an item is considered correct if it is recalled in the correct sequence relative to its neighbors, even if shifted from the absolute position ￼ ￼. For instance, if the target list was A–B–C–D–E–F–G and the person recalled A–B–C–F–G (skipping D and E), under relative-order scoring the sequence “A, B, C, F, G” would get credit for B and C following A as intended and for G following F, even though D and E were omitted ￼. The idea is that after a gap, the participant resumed the correct order. This method gives partial credit for maintaining relative sequence and is useful when participants can leave blanks or when analyzing recall where omissions occur. Another lenient measure sometimes reported is item-wise accuracy regardless of position – essentially treating the task like free recall for scoring purposes (did the person recall this item at all, in any position?). This separates memory for items from memory for order. In serial recall experiments, researchers might report item recall (percent of list items recalled in any order) versus order recall (how many were also in the correct position) to distinguish these components. For evaluating models, it can be informative to look at both strict serial recall performance and a more lenient measure, especially if a model might produce transpositions. However, unless otherwise specified, the default for serial position curves in ordered recall is the strict item-in-position criterion.

Omissions and guesses are handled within these scoring schemes as well. If a participant skips a position (failing to recall any item for that slot), that is scored as an error for that position. If they insert an extra item that wasn’t on the list (an intrusion error), it doesn’t directly affect the scoring of a particular position unless it displaces the correct item (in strict scoring, an intrusion means the correct item for that position wasn’t produced, so it’s an error for that position). In summary, to compute a serial position curve under strict scoring, one would take the number of trials (or lists) in which the item at position i was recalled in its correct position and divide by the total number of trials – yielding the proportion correct at position i. Plotting these proportions against position gives the serial position curve for serial recall.

Handling Repeated Items in a List

One complication in serial recall is the presence of repeated items within a list (e.g., a list where a word appears twice). Standard serial recall experiments often avoid within-list repetitions of an item because they can induce specific interference effects. When repeats are present, researchers must clarify how scoring is done and be aware of the so-called Ranschburg effect. The Ranschburg effect is the empirical finding that when an item is repeated in a sequence, people have difficulty correctly recalling the second occurrence of that item ￼ ￼. In other words, repeated items tend to be recalled worse than non-repeated items at the same positions, even though one might think repetition would help. This effect is “localized primarily at the position of the second occurrence of the repeated item” ￼ and does not strongly impair memory for other items in the list (the items following the repeat are typically recalled about as well as they would be otherwise). It appears that participants often omit one of the repeats or recall it in the wrong place, likely due to a bias against repeating themselves or confusion about whether they already said that item ￼. In scoring, each occurrence of a repeated item is treated as a separate target: to get full credit, the participant must recall both instances in their respective positions.

When computing accuracy by serial position in lists with repeats, one should still use the same item-position criterion, but carefully interpret performance on those positions. If the list had item “X” at position 3 and again at position 7, for example, then position 3 is scored correct if “X” was recalled first, and position 7 is scored correct if “X” was recalled in the 7th output. It’s possible a person recalls only one “X” (thus one of those positions gets an omission) or recalls “X” twice but mis-ordered (though if they produce two X’s, and both target slots are X, any order they produce two X’s will fill both slots – making it tricky to tell if a transposition occurred because the items are identical). Researchers sometimes instruct participants explicitly when repeats occur (“the list may contain repeats”) to encourage them to output two instances. If a participant recalled fewer instances of the repeated item than were presented, the missing occurrence is an omission. If they recalled an extra instance beyond what was in the list, that extra is an intrusion (often called a repetition error or “repeated response” error, which is generally rare ￼).

Notably, the magnitude of the Ranschburg effect can depend on the spacing of the repeats. Classic studies showed that if the two occurrences are far apart in the list, recall of the second occurrence is much worse (“repetition inhibition”), whereas if the repeats are adjacent or very close together, people sometimes recall them better than expected (“repetition facilitation”) ￼. Henson (1998) demonstrated this in a series of experiments: when repeated items were contiguous, participants often noticed the repetition and could “tag” it, leading to high accuracy for both (e.g. saying “X, X” in order with little problem), but when repeats were spaced out, participants would frequently fail to produce the second one ￼. There also appears to be a bias against guessing that an item repeated – participants may avoid responding with an item twice unless they are fairly sure, which contributes to the second occurrence being dropped or replaced by a wrong item ￼ ￼.

Scoring suggestions for repeats: If you are plotting serial position accuracy and some positions correspond to repeated items, include those positions in the curve but note the lower performance likely reflects repetition difficulty (and not just random fluctuation). You may even plot a separate curve or symbol for repeated-item positions if you want to highlight the effect. Some analyses compare repeated-item positions to “control” positions from lists without repeats ￼. For model evaluation, ensure the model’s scoring accounts for repeats similarly – e.g. if the model outputs only one instance of a repeated item, that should count as a miss for the other occurrence. In human data, it’s typical to see the second occurrence of a repeated item having notably lower accuracy than other positions ￼. Importantly, repeated items do not generally cause a cascade of errors on subsequent items (which would be expected under a simple chaining model); instead, the error is specific to the repeated item itself ￼. This implies people often recall the rest of the list normally despite failing to recall a repeat properly. Thus, when plotting data, the serial position curve might show a dip at the repeated item’s second position, but not necessarily drops at later positions (assuming lists are randomized such that repeats aren’t always at end, etc.).

In summary, handle repeated items by treating each occurrence as its own target in scoring, but be aware that human recall data will likely show a systematic deficit for those positions (Ranschburg effect) unless the repeats are adjacent. If adjacent repeats are present, participants often recall them together (sometimes scoring procedures count a run of the same item as correct as long as the number of repeats matches – depending on instructions). Always clarify scoring criteria in any report (some studies have employed specialized scoring for repeats ￼, but the safest approach is to stick to standard positional scoring while noting any peculiarities due to identical items).

Transposition Errors and Serial Position Curves

In serial recall data, errors can be classified broadly into item errors (recalling a wrong item that wasn’t in that position or not in the list at all) and order errors. The most common order error is a transposition, where a list item is recalled in a position different from its original one. Under strict scoring, transpositions are all considered errors (the item isn’t in the correct slot), but analysts often examine transposition errors in more detail because they reveal how the order memory failed. A key finding is that transposition errors are usually local: items tend to wander only a short distance from their correct position. In other words, if an item is recalled in the wrong serial position, it is very often a position near the correct one (e.g. an item from position 5 might show up in position 4 or 6 more frequently than in position 1 or 10). This tendency for items to be recalled near their true position is known as the locality constraint ￼. Empirically, “most transpositions occur over short distances” ￼. For example, Henson et al. (1996) found that in immediate serial recall, when errors occurred, items were far more likely to swap with an adjacent position than to jump across the list ￼.

To quantify this, researchers plot transposition gradients ￼. A transposition gradient is a plot of the probability of an error as a function of how far away the item was from its correct position. The displacement is often measured in positions (e.g. −1 means the item was recalled one position earlier than it should have been – an “anticipation” error – and +1 means it was recalled one position later than correct – a “postponement” error). When you plot the frequency of errors at each displacement (excluding the zero displacement which are correct recalls), the typical result is a sharply peaked distribution centered at displacement 0, dropping off as displacement increases ￼. In practical terms, this means if an item is misplaced, it’s usually only by a small amount. Figure 2A in Hurlstone et al. (2014) illustrates this: the probability of a transposition error decreases as the absolute displacement increases, forming an approximately inverted-U shape (if we look at absolute distance) or a steeper drop on either side of zero (if we distinguish + and – displacements) ￼. This is a consistent finding across many serial recall experiments and even in other domains (spatial sequences, musical note sequences, etc.), indicating that positional memory has a strong local component ￼.

Furthermore, there is often a slight asymmetry in the transposition gradient: anticipation errors (item recalled too early, negative displacement) tend to be more frequent than postponement errors. Participants are more likely to “pull in” an item from a later position and say it too soon (leaving its original slot empty or filled incorrectly) than to skip an item and recall it too late. This manifests as a bias where items often appear earlier than they should. Empirical studies have noted this asymmetry – more negative displacement errors – especially in tasks without response deadline ￼. The result is that the transposition gradient might not be perfectly symmetric; typically the −1 displacement is a bit higher than the +1. There is also a phenomenon called fill-in errors: if an item is recalled too early, often the item that was skipped will later appear where the prematurely recalled item should have been. For example, if the correct order is A–B–C and someone mistakenly recalls B, A, C (B came too early and A was delayed), that pattern is called a fill-in (the earlier item A eventually filled in the gap) as opposed to an infill (a later item filling in a gap left by an early item). Fill-in errors are more common than infill errors ￼, consistent with the idea that if something comes out of order, the mind often tries to correct by outputting the missing earlier item soon after. This creates dependencies between errors: an anticipation error for item i+1 often co-occurs with a postponement (or late recall) of item i. These nuances might be beyond what a basic serial position curve shows, but they are important in detailed model evaluation. Many memory models of serial order are explicitly tested against the transposition gradient and these error patterns ￼ ￼.

Implications for plotting and scoring: For basic serial position curves, all transposition errors simply cause a decrement in accuracy at the affected positions (since the item wasn’t correct in its intended slot). But it’s useful to analyze and possibly visualize transpositions separately. One could include an additional plot or figure showing, for each position, where those items ended up when they were wrong. This is sometimes done with confusion matrices or displacement frequency plots. For example, one might create a matrix with input positions on one axis and output positions on the other, shading cells for frequency of recalls; most of the mass lies along the diagonal (correct recalls) and the immediately neighboring cells (adjacent transpositions) ￼. Alternatively, one plots the transposition gradient: on the x-axis the displacement (−(N−1)…−1, +1…+(N−1)), on the y-axis the probability of that displacement given a recall error. This typically shows a peak at displacement = ±1 and a rapid fall-off ￼. When evaluating a model, you may want to compare its transposition gradient to human data in addition to the serial position curve, as a good model should not only capture primacy/recency but also produce mostly local order errors, not random positioning.

In terms of scoring, if using strict criteria, each transposition entails two position errors (one item is out of place, and the position where it should have been is incorrect). Some researchers use a scoring method based on minimum edit distance (e.g., how many insertions/deletions needed to turn the recalled sequence into the correct sequence) as an alternative that can give partial credit for near-misses ￼. Such methods go beyond the simple serial position curve, but can be useful for nuanced scoring (e.g., counting an adjacent swap as “less wrong” than a distant swap). If the context of your analysis is standard, it’s safest to present the serial position curve with strict scoring, and if needed, report separate analyses of order errors (like “X% of errors were adjacent transpositions” etc.).

Visualizing Serial Recall Performance

Serial position curve plots. The conventional way to visualize serial recall accuracy is a line graph (or bar graph) of position (serial position of the item in the study list) on the x-axis against probability of correct recall on the y-axis. Each point or bar represents the proportion of trials in which that position was recalled correctly (with whatever scoring criterion is chosen, usually strict). Such curves in immediate serial recall of verbal lists often show a bowed shape – high performance at the beginning (primacy effect), a drop in the middle, and sometimes a modest uptick at the end (recency effect). The primacy effect in serial recall is typically strong, as the first few items often have the highest recall (possibly due to rehearsal or distinctiveness). The recency effect in strict serial recall is more variable: if recall is truly strictly ordered (participants must recall item1, then item2, etc., without skipping), then a forgotten item can truncate recall of later ones. In practice, however, participants often attempt all positions, so one often still sees an advantage for the last one or two items – especially if participants can get to them (for example, they might recall the final items easily since they were the most recent in memory). Recency in serial recall is usually smaller than recency in free recall because the requirement to report in order means participants can’t simply output the last items first (which in free recall they do). If a distraction or delay is introduced before recall, recency can vanish (similar to free recall). In immediate serial recall with auditory presentation, a robust last-item advantage is sometimes observed (the terminal item benefits from echoic memory). Generally, though, expect a gently rising tail at the end rather than the very steep recency seen in free recall curves ￼.

When plotting, include error bars or confidence intervals if available, to show variability at each position. If comparing conditions (e.g., control vs experimental manipulation, or model vs human), you can plot two curves on the same graph for the serial position effect. The x-axis should be “Input Serial Position” (1 = first item, etc.). Often researchers label the curve points with the actual item positions. You may annotate special positions (like if position 5 had a repeated item, you could mark it with an asterisk or different color, since, as noted, that might depress performance).

Transposition gradients and other error plots. It is often helpful to visualize not just accuracy, but the distribution of errors. A transposition gradient plot (as described above) can be included to illustrate the locality of order errors. For example, one could plot a bar for proportion of errors that were displacement of +1, +2, etc., and −1, −2, etc. (Typically, one finds the ±1 errors are most common, with very few beyond ±3 in immediate recall ￼ ￼.) If your memory model provides output sequences, you can derive a transposition gradient from its errors and compare it to human data. A close match would indicate the model captures human-like order constraints. Another visualization is an input-output position matrix (sometimes called a confusion matrix for serial recall). On such a heatmap, correct recalls show up on the main diagonal, and transpositions show up as off-diagonals – most intensity will be near the diagonal if locality holds. This kind of plot can quickly show if a model is making only local errors or more random ones.

For illustrating the Ranschburg effect or repeated items, you might plot separate serial position curves for lists that contained a repeat vs lists that did not, or simply mark the repeated-item positions on the curve. Empirically, one would see a dip at the second occurrence position on the curve for repeated-item lists ￼. If you have enough data, you could even plot conditional probabilities (e.g., probability of recalling the second instance given the first was recalled, etc.), but that goes deeper than a standard serial position curve. Often a simpler summary is given: e.g., “the probability of recalling the second occurrence was only ~40%, versus ~60% for control items” – and this would be apparent as a downward point on the serial position plot.

Example serial position curves for a strict serial recall task vs a free recall task (illustrative data). The orange line (circles) shows serial recall accuracy by position, exhibiting a strong primacy effect and a mild recency effect. The red line (squares) shows free recall probability by original position from the same lists – note the enhanced recency (higher recall of last items) and a somewhat lower mid-list performance in free recall. In free recall, participants tend to output the last few items first, boosting their recall odds ￼, whereas in serial recall they must recall in order, making it harder to retain late items if earlier ones are forgotten.

In the illustrative figure above, we see that for free recall (red line) the last item has the highest recall probability (a strong recency effect), whereas in serial recall (orange line) the last item is not as disproportionately high because the person had to recall all prior items before getting to it. The first item is high in both cases (primacy), though often even higher in serial recall because people focus on getting the start of the sequence correct (and in models, often a primacy gradient of attention is assumed). The middle items are the lowest in both, which is typical. When comparing model output to human data, one should ensure the model’s curve shows this general shape under serial recall conditions. If a model were producing, say, a flat serial position curve or too much recency, that would signal a mismatch with human serial recall data.

Serial vs. Free Recall Serial Position Curves

It’s important to distinguish serial recall from free recall when interpreting serial position curves. In free recall, participants can recall list items in any order they wish. Consequently, free recall curves are usually plotted by taking each item’s original list position and computing the probability that the item was eventually recalled (regardless of output position). The classic free recall curve shows a pronounced primacy effect and often an even more pronounced recency effect ￼. People tend to begin recall with end-of-list items (those are still in short-term memory) ￼, which is why those late serial positions have very high recall rates in free recall. In immediate free recall, the last few items might be remembered nearly perfectly. In serial recall, by contrast, participants are constrained to recall in order, so they cannot take advantage of the recency items immediately. If the task is strictly enforced, forgetting an early item can prevent later items from being recalled (sometimes experimenters instruct that if you don’t know an item, you should guess or say something and move on – but the need to output something can still cause delays or confusion that hurt later recall). Thus, recency is typically smaller in serial recall curves. Primacy tends to occur in both tasks, though models attribute it to slightly different mechanisms (extra rehearsal in free recall vs. extra weighting or distinctiveness in serial recall).

Another difference is in error patterns: free recall has no concept of “transposition errors” in the same way, since order is irrelevant. Instead, free recall analysis looks at phenomena like temporal clustering (the tendency to successively recall items that were near each other in the list). This is somewhat analogous to transposition analysis: in free recall, if people tend to recall item 5 and then item 6 together, that indicates memory for that local grouping. But they won’t be penalized for outputting item 6 before item 5; both count as correct. In serial recall, doing 6 before 5 is an error (transposition). So serial recall curves (strict) are a harsher measure. If one were to score free recall data in a way similar to serial (requiring items to be in the original position), performance would look much worse. Conversely, if one rescored serial recall data in a free-recall manner (credit for recalling items in any order), the overall recall rates would be higher.

In essence, serial position curves in free recall reflect output probability by position, with recency boosted by strategic output order ￼. Serial position curves in serial recall reflect accuracy of recall-in-place, with primacy and recency reflecting more inherent memory strengths (primacy from long-term encoding, recency from residual short-term memory) under the constraint of sequential output. Empirically, a free recall curve might show a very steep drop in middle, whereas a serial recall curve often looks “flatter” in the sense that recency isn’t sky-high (because participants can’t exploit short-term memory as directly). For example, in a 15-item list free recall, positions 13–15 might each be recalled ~80% of the time, whereas in serial recall of 15 items, position 15 might only be correct 50% of the time (since if earlier mistakes happened, item 15 might never be reached or might be forgotten by the time one gets there).

When using serial position data to evaluate a memory model, make sure you are comparing like to like. If the model simulates a free recall process, you’d compare its output to free recall curves; if it’s meant to do serial recall, compare to serial recall curves. Some models can be run in both modes. The differences highlight that serial recall is more demanding of order information. A good model of serial recall should account not only for the U-shaped accuracy curve but also for the tight transposition gradient (most errors are items swapping with neighbors) ￼ and phenomena like the Ranschburg effect for repeats ￼. Free recall models often emphasize retrieval dynamics and contextual cues (e.g., temporal context model), which yield strong recency and temporal clustering, whereas serial recall models often emphasize positional coding or chaining with a mechanism to maintain an order constraint.

Summary of recommendations: Use strict scoring for primary analyses of serial recall serial position curves, but be clear about what “correct” means in this context. If applicable, report if you allowed participants to skip and how that was scored. Handle repeated items by counting each occurrence separately and note the expected difficulty on second occurrences (you might cite the Ranschburg effect to contextualize any odd dips). To visualize, a simple line graph of accuracy by position with error bars is standard; include primacy/recency labels in your discussion. For deeper analysis, include a transposition error plot or at least describe the nature of order errors (e.g., “errors tended to be adjacent transpositions, consistent with locality ￼”). When comparing to free recall, remember that free recall curves show what items were eventually recalled, whereas serial recall curves enforce order – thus differences in recency and overall level. By adhering to these conventions from the literature ￼ ￼ ￼, you can ensure your analysis and figures align with how cognitive psychologists typically present serial recall results, making your evaluation of the memory model both accurate and easy to interpret.

Sources:
	•	Henson, R. N. et al. (1996). Unchained Memory: Error Patterns Rule out Chaining Models of Immediate Serial Recall. Quarterly Journal of Experimental Psychology, 49A(1), 80-115. (Defines transposition, locality of errors) ￼
	•	Hurlstone, M. J., Hitch, G. J., & Baddeley, A. D. (2014). Memory for Serial Order Across Domains: An Overview. Psychological Bulletin, 140(2), 339-373. (Review of serial order phenomena; discusses scoring methods, transposition gradients, and repetition effects) ￼ ￼
	•	Mewaldt, S. P., & Hinrichs, J. V. (1973). The Ranschburg effect: Stimulus variables and scoring criterion. Memory & Cognition, 1(3), 177-182. (Demonstrated the Ranschburg effect – poorer recall of repeated items, primarily at second occurrence – and discussed influence of scoring criteria) ￼
	•	Kahana, M. J. (2012). Foundations of Human Memory. (Discusses serial and free recall differences, primacy/recency effects, and methodologies for scoring; see also Howard & Kahana, 1999 on free recall initiation) ￼
	•	Lewandowsky, S., & Farrell, S. (2008). Short-term memory: The ongoing debate. (Reviews models of serial recall and explains why strict positional scoring is typically used, and alternatives like relative-order scoring in some paradigms) ￼ ￼
	•	Additional references embedded in text: Ward (1937) on gains in middle positions across trials ￼; Bhatarah et al. (2006) on tendency for forward recall even in free recall; Conrad (1960) and others on fill-in vs infill errors ￼; and Crowder (1968) on repetition deficits ￼. These provide further empirical backing for the conventions described above.