Introduction
Paragraph 1 — The central puzzle.
Episodic memory must accomplish two seemingly incompatible goals: it must integrate successive experiences so that a retrieval cue can bridge temporal gaps, yet it must also discriminate among those experiences so that details of one encounter do not contaminate another. Retrieved‑context theory (RCT) instantiates this tension by positing a continuously evolving representation of temporal context that links items to the circumstances in which they were encountered [Howard & Kahana, 2002]. Over the past two decades, RCT has become the dominant framework for explaining both free‑ and serial‑recall phenomena, largely through the influential Context Maintenance and Retrieval (CMR) model and its relatives [Polyn et al., 2009; Lohnas et al., 2024]. Yet different implementations of RCT make different architectural and algorithmic commitments, and it remains unclear which of those commitments are essential to the theory’s explanatory reach.

Paragraph 2 — Divergent implementations.
CMR represents item–context relationships in a connectionist weight matrix and relies on a composite “item‑blend” rule to update context. By contrast, the Context Retrieval and Updating (CRU) model embeds each study episode in a trace (or instance) and has been shown to excel in strictly ordered tasks such as serial recall [Logan et al., 2018, 2021]. Because the two models differ on multiple fronts—architecture, positional coding, retrieval termination, and more—the field lacks a principled account of why each model succeeds where it does, and whether their differences reflect deep theoretical divides or merely alternative parameterisations of the same core ideas.

Paragraph 3 — A unifying perspective.
This dissertation argues that many apparent disagreements evaporate once we separate architectural form (connectionist vs. trace‑based) from algorithmic rules (how context is updated, how retrieval terminates). To that end, I introduce Instance‑CMR (ICMR), a trace‑based reformulation of CMR that reproduces every behavioural prediction of the original connectionist version with identical parameters. By showing that CMR’s behaviour does not depend on its connectionist substrate, ICMR turns architectural choice from a roadblock into a flexible modelling dimension. The framework then serves two purposes: it enables a head‑to‑head comparison of CMR and CRU on common benchmarks, and it provides configurable mechanisms—such as non‑overlapping contextual reinstatement and trace competition—for testing new theoretical claims.

Paragraph 4 — Chapter map.
Chapter 1 develops ICMR in full, offers a proof of functional equivalence to CMR, and demonstrates the match on classic free‑recall effects such as lag‑contiguity and primacy–recency gradients. Chapter 2 uses ICMR as neutral ground to dissect the algorithmic differences between CMR and CRU. Through a factorial model‑selection exercise on free‑ and serial‑recall data, it identifies which features (e.g., positional coding, recall‑termination cues) are necessary for each task and establishes a benchmark suite that the final chapter will leverage. Chapter 3 tackles an unresolved empirical puzzle: item‑blend implementations predict substantial associative interference from within‑list repetitions, yet a re‑analysis of six archival datasets reveals that such interference is minimal. Using ICMR’s configurable trace mechanisms, I show that allowing repetitions to reinstate unique, non‑overlapping contextual features and letting traces compete during retrieval resolves the discrepancy without degrading fits to the benchmarks defined in Chapter 2.

Paragraph 5 — Contributions and significance.
Together, the three chapters advance a unified agenda: clarifying where architecture ends and algorithm begins in retrieved‑context modelling, and demonstrating how flexible, trace‑based implementations can reconcile competing accounts while solving long‑standing empirical challenges. By providing open‑source code, detailed parameter analyses, and a configurable modelling toolkit, the dissertation offers both a theoretical synthesis and a practical foundation for future work on episodic memory, spacing effects, and trace‑competition dynamics.