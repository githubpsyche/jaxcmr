Absolutely—here’s a clean, publication‑ready draft of the **Results** narrative that pairs your empirical constraints with standard CMR’s predictions and follows the figure plan you’ve outlined. I keep the tone tight, avoid over‑heading, and tie each analysis back to the theoretical question of blending vs occurrence‑specific access.

---

## Reassessing empirical benchmarks against CMR

Before turning to repetition‑specific diagnostics, I verify that mixed and control lists are comparable once the matched, symmetric baseline is applied, and that standard CMR reproduces the benchmarks that any viable free‑recall account must capture. Figure @fig-control_method shows serial‑position curves (SPCs), lag‑conditional response probabilities (lag‑CRPs), and probabilities of first recall (PFRs) for mixed and control lists in @lohnas2014retrieved, plotted in raw form (left) and after baseline correction (right). In the raw SPCs, mixed lists appear to enjoy a mid‑list advantage; after position matching and symmetric scoring this inflation vanishes, and SPCs from mixed and control lists are essentially indistinguishable. Small raw differences in the lag‑CRP likewise disappear under the baseline, and the PFRs are virtually identical across conditions. These checks establish that, once opportunities for recall are equated, mixed lists are not globally “easier,” and that any residual differences must arise from the structure imposed by repetition rather than list composition per se.

Standard CMR reproduces these benchmarks under the same scoring (Figure @fig-control_method, bottom). SPC, lag‑CRP, and PFR profiles generated by the fitted model track the corrected data closely. This alignment rules out a “bad‑fit” explanation for any discrepancies that emerge on the repetition‑specific tests below: the model’s core machinery for temporal organization is intact, and the remaining tension must therefore concern how it handles repeated items.

## The spacing effect

Figure @fig-spacing displays the spacing function for mixed and control lists in @lohnas2014retrieved alongside fitted CMR simulations. In the data, recall for repeated items rises monotonically with lag, with the mixed‑vs‑control contrast largely absorbed by the baseline correction. Standard CMR captures the overall monotone trend and gross spacing magnitude, confirming that its temporal‑context dynamics and primacy scaling are sufficient to produce a spacing advantage under matched scoring. Where the model begins to drift is not in the existence of spacing, but in how spacing coexists with (or resists) cross‑occurrence associative pull—precisely what the next diagnostics target.

The spacing effect is classically understood as a repetition effect and has been a central focus of research on memory for repeated experience \[@cepeda2006distributed]. However, it also appears for pairs of distinct items. Using the probability of retrieving **either** member of a pair during free recall—the “OR score”—studies often find that spaced pairs are recalled more often than massed pairs \[@lohnas2011contextual]. Notably, in “superadditivity,” the mnemonic benefit of spacing is argued to be larger for repeated items than for distinct-item pairs: the probability of recalling a spaced repetition can exceed the OR probability for two distinct items at a comparable spacing, violating statistical independence \[@benjamin2010makes].

In the Lohnas & Kahana dataset, the spacing function estimated from **mixed lists** appears **steeper** than the function derived from our position‑matched, symmetric baseline (left panel of @fig-spacing). Because the baseline equates list length, presentation schedule, and scoring opportunity, the slope difference cannot be attributed to serial‑position or scoring artifacts; it suggests a repetition‑specific boost over and above the spacing effect observed for equally spaced distinct items (i.e., a superadditive component). Standard CMR, by contrast, reproduces the **overall** monotonic spacing advantage but shows **no** corresponding slope separation between mixed and baseline conditions (right panel of @fig-spacing). Thus, while CMR captures the basic memorability gain with increasing lag, it does not express the additional repetition‑specific steepening present in the data, foreshadowing the model‑variant results that follow.


## Cross‑occurrence neighbor transitions

The neighbor‑contiguity analysis (recast as a centered lag‑CRP) asks whether study or retrieval blends the neighborhoods of the two occurrences. In the **data** (top row of Figure @fig-neighbor_contiguity), when the trigger sits near one occurrence (e.g., $i{+}1$ or $i{+}2$), the centered lag‑CRP around the *other* occurrence overlays its matched baseline. There is no selective elevation of cross‑occurrence neighbors; the mixed–minus–baseline curve is flat within noise. The same is true when roles of $i$ and $j$ are reversed. In short, a local cue to one occurrence does not behave as if it partially reinstates the other occurrence’s context.

Standard **CMR** (bottom row) predicts the opposite pattern. Triggering in one neighborhood boosts the other neighborhood’s immediate neighbors above baseline, with the familiar forward skew, reflecting blended reinstatement across occurrences. This is the characteristic associative‑interference signature: cross‑occurrence neighbors are pulled up, even when the repeater itself is not recalled. The absence of this signature in the data is the first clear indication that item‑based blending is too strong as implemented.

Here’s a refined, drop‑in rewrite for the **Cross‑occurrence neighbor contiguity** section that (i) clearly distinguishes the two variants without using “i2j/j2i,” (ii) states CMR’s predictions for each, and (iii) highlights the empirical lag‑0 effect you observe only in the first→second variant. Figure references follow your Quarto style for **@fig-neighbor_contiguity**.

---

### Cross‑occurrence neighbor contiguity (free recall)

This analysis tests whether repetition links the neighborhoods surrounding the two study positions of a repeated item. We use the centered lag‑CRP recast described above, with triggers confined to forward neighbors (+1 or +2) of one occurrence and lags centered on the *other* occurrence, and we compare mixed lists to the matched, symmetric baseline.

We examine two symmetric variants, shown in the top row of **@fig-neighbor_contiguity**. In the **first→second** variant (left column), transitions are triggered by recalls of the forward neighbors of the *first* presentation (positions $i{+}1$ or $i{+}2$), and the lag‑CRP is centered on the *second* presentation at $j$ (so $\ell=\text{next}-j$). In the **second→first** variant (right column), triggers are the forward neighbors of the *second* presentation ($j{+}1$ or $j{+}2$), and the lag‑CRP is centered on the *first* presentation at $i$ (so $\ell=\text{next}-i$). As before, all probabilities condition on eligibility and the baseline uses position‑matched control lists with symmetric scoring.

**CMR’s prediction.** Because study‑phase reinstatement pulls the two occurrence contexts together and retrieval reinstates a composite tied to the repeated item, CMR predicts elevated cross‑occurrence neighbor transitions in *both* directions: after a trigger in one neighborhood, the next recall should be above baseline at the other neighborhood’s immediate lags (typically with the usual forward skew). These predictions are confirmed in the simulations (bottom row of **@fig-neighbor_contiguity**), which show clear above‑baseline mass near $\ell=\pm1,\pm2$ in both variants.

**Empirical pattern.** The data tell a different story. In both variants, mixed–minus–baseline curves show little to no elevation at the other occurrence’s neighbors (top row of **@fig-neighbor_contiguity**). Thus, we do not see the predicted knitting of the two neighborhoods. However, there is a selective effect not anticipated by CMR: in the **first→second** variant (left), transitions to the *repeated item itself* (lag $=0$, conditional on availability) are **elevated** relative to baseline. This lag‑0 bump does **not** appear in the **second→first** variant (right), nor do we observe the robust cross‑neighbor boosts that CMR predicts in either direction.

**Interpretation.** The absence of above‑baseline neighbor‑to‑neighbor transitions argues against a blended neighborhood linkage as the dominant consequence of repetition. The asymmetric lag‑0 elevation—visible only when moving from the first occurrence’s neighborhood toward the second—suggests that repetition can heighten access to the repeated item without knitting the two neighborhoods together. We return to this selective lag‑0 effect when introducing the ICMR‑Reinf variant, which replaces associative blending at study with reinforcement of the first‑occurrence trace and better accommodates this pattern.

\::: {#fig-neighbor_contiguity layout="\[\[1,1], \[1,1]]"}

![Data.](../../figures/fits/LohnasKahana2014_mixedvscontrolA_data_Model_Comparison_LT4_repneighborcrp_i2j.png)

![Data.](figures/LohnasKahana2014_mixedvscontrolA_data_full_best_of_3_LT4_repneighborcrp_j2i.png)

![Standard CMR.](figures/LohnasKahana2014_mixedvscontrolA_WeirdCMR_full_best_of_3_LT4_repneighborcrp_i2j.png)

![Standard CMR.](figures/LohnasKahana2014_mixedvscontrolA_WeirdCMR_full_best_of_3_LT4_repneighborcrp_j2i.png)

**Cross‑occurrence neighbor contiguity as centered lag‑CRPs (free recall).**
Top row (data), bottom row (CMR simulations). **Left column (first→second):** triggers are forward neighbors of the *first* presentation ($i{+}1,i{+}2$); lags are centered on the *second* presentation at $j$ (so $\ell=\text{next}-j$). **Right column (second→first):** triggers are forward neighbors of the *second* presentation ($j{+}1,j{+}2$); lags are centered on the *first* presentation at $i$ (so $\ell=\text{next}-i$). All curves plot mixed–minus–matched‑control probabilities using the symmetric baseline. In the data, cross‑occurrence neighbor bins (e.g., $\ell=\pm1,\pm2$) sit near baseline in both directions, with a selective elevation at $\ell=0$ (the repeater itself) only in the first→second case. Standard CMR predicts pronounced above‑baseline peaks at the other occurrence’s neighbors in both directions, consistent with associative blending. :::


## The repetition lag‑CRP

The outgoing repetition lag‑CRP quantifies how a recalled repeater cues subsequent recall from each occurrence’s neighborhood (Figure @fig-repetition_lag_crp). In the **data**, transitions from the repeated item preferentially target the first‑occurrence neighborhood: the $+1$ bin from the first‑centered cue exceeds the $+1$ bin from the second‑centered cue, and this *separation* is larger than in the position‑matched baseline. Thus, relative to controls, repetition does not balance the two neighborhoods; it accentuates access to the first occurrence’s neighbors.

Standard **CMR** again moves in the wrong direction. Because the repeater cue aggregates across occurrence‑specific context, the model predicts *more balanced* access to first‑ and second‑occurrence neighborhoods than in the baseline (i.e., a reduced separation). The data instead show a boosted separation that favors the first occurrence. This conflict isolates the problem: when the repeater is recalled, the model’s item‑based reinstatement routes through a composite of contexts, whereas people’s recalls behave as if a single occurrence’s context is (selectively) reinstated.

## Repetition lag‑CRP (incoming)

The incoming (backward) variant asks whether the asymmetry observed above is already present in the recalls that *precede* a repeater. In the **data**, incoming curves are comparatively balanced across the two centers, with much smaller first‑over‑second advantages than on the outgoing analysis (Figure @fig-backward_rep_lag_crp). Any residual bias on incoming transitions is well accounted for by the position‑matched baseline (e.g., primacy and spacing structure), and the mixed–minus–baseline contrast is near zero. Thus the first‑over‑second advantage emerges primarily **after** the repeater is produced, implicating the repeater‑driven reinstatement process rather than the global cue state before the repeater.

Standard **CMR**’s predictions mirror its outgoing behavior: incoming transitions are too balanced relative to baseline—not a failure per se, but they do not rescue the model from the outgoing discrepancy. Together, the two variants point squarely to the reinstatement rule attached to the repeated item, not to differences in how the list context gets to the repeater.


**Repetition lag‑CRP (incoming/backward).** This variant asks how people *arrive* at repeated items. For each recall of a repeater, we look one step back to the item produced immediately before it and compute two centered lag‑CRPs—one centered on the first presentation and one on the second—using the matched, symmetric baseline to control position effects. In the data (@fig-backward_rep_lag_crp, top row), arrivals at repeaters come disproportionately from the backward neighbor of the *first* presentation (from $i{-}1$ to $i$) compared with the backward neighbor of the second (from $j{-}1$ to $j$). The preference is strongest in mixed lists but is also evident in the position‑matched baseline, indicating that it reflects general serial‑order dynamics (e.g., forward contiguity and output competition) rather than repetition‑specific knitting per se. Standard CMR yields only a weak first‑over‑second advantage on these incoming transitions (@fig-backward_rep_lag_crp, bottom row), consistent with the model’s tendency to aggregate support across a repeater’s occurrences and thereby dilute approach biases. Practically, this pattern cautions that any first‑over‑second asymmetry seen *after* recalling a repeater (the outgoing analysis) may be partly inherited from how the search state approached the repeater; the mixed–minus–baseline contrast in the outgoing test is therefore the cleaner probe of repetition‑specific reinstatement.


## Forward chaining in serial recall

Serial recall provides a more stringent test of cross‑occurrence competition. In the **data** from @logan2021serial, after participants correctly type through the first occurrence at position $i$, continuations to $i{+}1$ remain strong, and erroneous continuations to the competing neighbor $j{+}1$ are rare and indistinguishable from the matched control baseline. That is, the second occurrence’s neighborhood does **not** draw responses away from the correct forward chain.

Standard **CMR** predicts a measurable elevation of $i\!\rightarrow\!j{+}1$ errors relative to baseline, again reflecting blended support across occurrences. The absence of this cross‑occurrence forward error in the data generalizes the non‑interference finding from free recall to a serial‑order task: whether the next step is unconstrained (free recall) or constrained (serial recall), occurrences behave as if support is routed through a single episode.

:::


:::

## Summary: non‑interference across tasks

Across three diagnostics and two tasks, the same pattern recurs. When we remove list‑composition artifacts with a matched, symmetric baseline, free recall **does not** show elevated cross‑occurrence neighbor transitions, and the repeated item **does not** balance access to the two neighborhoods; instead, access is preferentially routed to the first occurrence’s neighbors. In serial recall, the first occurrence’s forward chain remains intact, with no detectable attraction to the second occurrence’s neighbors. Standard CMR fits the classic benchmarks and the spacing function, but its item‑based reinstatement produces a robust associative‑interference signature that the data do not support. This motivates the mechanistic analysis that follows, which alters how contextual features are reinstated at study and at test—first by removing study‑phase reinstatement (CMR‑NoSPR), then by allowing occurrence‑specific reinstatement at retrieval (ICMR‑OS), and finally by rehabilitating study‑phase retrieval as **reinforcement** rather than **blending** (ICMR‑Reinf)—to reconcile retrieved‑context theory with the observed non‑interference.

---

Perfect—below are Quarto figure blocks you can paste directly into your draft under **Reassessing empirical benchmarks against CMR**. I’ve matched your house style (triple‑colon divs, `layout=` grids, paragraph caption after the images) and kept labels unique. I’ve also spelled out how to arrange the subfigures in each caption. You can swap in your exact file names/paths; I’ve used your demonstrated naming conventions as placeholders.

---

\::: {#fig-control_method layout="\[\[1,1], \[1,1], \[1,1]]"}
![](figures/RepeatedRecallsLohnasKahana2014_mixedvscontrolB_data_full_best_of_3_LT4_spc.png)
![](figures/RepeatedRecallsLohnasKahana2014_mixedvscontrolA_data_full_best_of_3_LT4_spc.png)
![](figures/RepeatedRecallsLohnasKahana2014_mixedvscontrolB_data_full_best_of_3_LT4_crp.png)
![](figures/RepeatedRecallsLohnasKahana2014_mixedvscontrolA_data_full_best_of_3_LT4_crp.png)
![](figures/RepeatedRecallsLohnasKahana2014_mixedvscontrolB_data_full_best_of_3_LT4_pnr.png)
![](figures/RepeatedRecallsLohnasKahana2014_mixedvscontrolA_data_full_best_of_3_LT4_pnr.png)

**Benchmark data with and without the matched, symmetric baseline (Lohnas & Kahana, 2014).** Grid is 3 rows × 2 columns. Left column in each row: **raw** mixed vs control. Right column: **baseline‑corrected** using serial‑position matching with symmetric scoring. Top row: serial‑position curves (SPC). Middle row: lag‑CRP. Bottom row: probability of first recall (PFR). After correction, mixed and control lists are closely aligned on all benchmarks. :::

---

\::: {#fig-cmr_benchmarks layout="\[\[1,1],\[1]]"}
![](figures/LohnasKahana2014_mixedvscontrolA_WeirdCMR_full_best_of_3_LT4_spc.png)
![](figures/LohnasKahana2014_mixedvscontrolA_WeirdCMR_full_best_of_3_LT4_crp.png)
![](figures/LohnasKahana2014_mixedvscontrolA_WeirdCMR_full_best_of_3_LT4_pnr.png)

**Standard CMR on the same benchmarks (matched scoring).** Arrange as 2 panels on top, 1 on bottom. Top‑left: SPC. Top‑right: lag‑CRP. Bottom: PFR. Fitted CMR reproduces the baseline‑corrected benchmark profiles, ruling out a global misfit and focusing attention on repetition‑specific predictions. :::

---

\::: {#fig-spacing layout="\[\[1,1]]"}
![](figures/RepeatedRecallsLohnasKahana2014_mixedvscontrolA_data_full_best_of_3_LT4_full_rpl.png)
![](figures/LohnasKahana2014_mixedvscontrolA_WeirdCMR_full_best_of_3_LT4_full_rpl.png)

**Spacing functions: data vs CMR (Lohnas & Kahana, 2014).** Two columns. Left: data (mixed and control, baseline‑corrected). Right: fitted CMR. Both show a monotonic spacing advantage; discrepancies emerge not in the existence of spacing but in how spacing coexists with cross‑occurrence organization tested below. :::

---

\::: {#fig-neighbor_contiguity layout="\[\[1,1], \[1,1]]"}
![](figures/LohnasKahana2014_mixedvscontrolA_data_full_best_of_3_LT4_repneighborcrp_i2j.png)
![](figures/LohnasKahana2014_mixedvscontrolA_data_full_best_of_3_LT4_repneighborcrp_j2i.png)
![](figures/LohnasKahana2014_mixedvscontrolA_WeirdCMR_full_best_of_3_LT4_repneighborcrp_i2j.png)
![](figures/LohnasKahana2014_mixedvscontrolA_WeirdCMR_full_best_of_3_LT4_repneighborcrp_j2i.png)

**Cross‑occurrence neighbor transitions as centered lag‑CRPs (free recall).** Arrange as 2 rows × 2 columns. **Top row (data):** left panel triggers from second‑occurrence neighbors and centers on the first; right panel triggers from first‑occurrence neighbors and centers on the second. **Bottom row (CMR):** same two variants from simulations. In the data, mixed–minus–baseline curves are flat near the alternative occurrence’s neighbors; CMR predicts elevated cross‑occurrence neighbor peaks (associative blending). :::

---

\::: {#fig-repetition_lag_crp layout="\[\[1,1], \[1,1]]"}
![](figures/RepeatedRecallsLohnasKahana2014_mixed_data_full_best_of_3_LT34_rep_crp.png)
![](figures/RepeatedRecallsLohnasKahana2014_control_data_full_best_of_3_LT34_rep_crp.png)
![](figures/RepeatedRecallsLohnasKahana2014_mixed_WeirdCMR_full_best_of_3_LT34_rep_crp.png)
![](figures/RepeatedRecallsLohnasKahana2014_control_WeirdCMR_full_best_of_3_LT34_rep_crp.png)

**Repetition lag‑CRP (outgoing): data vs CMR.** Arrange as 2 rows × 2 columns. **Top row (data):** mixed lists (left) and matched‑control baseline (right), each showing two centered curves (first‑centered vs second‑centered). **Bottom row (CMR):** same for simulations. In data, separation (e.g., $+1$ bin) favors the first‑occurrence neighborhood and is **larger** than in baseline; CMR predicts **reduced** separation (balanced access), consistent with blending. :::

---

\::: {#fig-backward_rep_lag_crp layout="\[\[1,1], \[1,1]]"}
![](figures/RepeatedRecallsLohnasKahana2014_mixed_data_full_best_of_3_LT34_back_rep_crp.png)
![](figures/RepeatedRecallsLohnasKahana2014_control_data_full_best_of_3_LT34_back_rep_crp.png)
![](figures/RepeatedRecallsLohnasKahana2014_mixed_WeirdCMR_full_best_of_3_LT34_back_rep_crp.png)
![](figures/RepeatedRecallsLohnasKahana2014_control_WeirdCMR_full_best_of_3_LT34_back_rep_crp.png)

**Repetition lag‑CRP (incoming): data vs CMR.** Same layout as @fig-repetition_lag_crp. **Top row (data):** mixed lists (left) and baseline (right) for transitions **to** repeated items. **Bottom row (CMR):** simulations. In data, incoming transitions are comparatively balanced across centers and well explained by baseline; the strong first‑over‑second advantage appears mainly **after** the repeater is produced. :::

---

\::: {#fig-forward_chain layout="\[\[1,1], \[1,1]]"}
![](figures/Logan2021Serial_data_forward_chain_mixed.png)
![](figures/Logan2021Serial_data_forward_chain_control.png)
![](figures/Logan2021Serial_CMR_forward_chain_mixed.png)
![](figures/Logan2021Serial_CMR_forward_chain_control.png)

**Forward chaining in serial recall (Logan et al., 2021, Exp. 2).** Arrange as 2 rows × 2 columns. **Top row (data):** mixed lists (left) and matched‑control baseline (right). Each panel plots the conditional probability of the **correct** transition $i\!\rightarrow\!i{+}1$ and the **cross‑occurrence forward error** $i\!\rightarrow\!j{+}1$ after correct report through position $i$. **Bottom row (CMR):** the same measures from simulations. Data show intact chaining and no elevation of $i\!\rightarrow\!j{+}1$ errors relative to baseline; CMR predicts a measurable error elevation, consistent with blended support across occurrences. :::

---

If you decide to split any figure into separate schematics and results panels (e.g., add a small legend or schematic panel), just extend the `layout=` grid and drop the extra PNG(s) at the appropriate slot; the captions above already specify the intended row/column semantics so readers can follow the panel logic.

---

Yes—if each panel plots only the **cross‑occurrence forward error**, you should tweak the results text to match and update the caption. Here’s a clean, drop‑in revision for the **Forward Chaining in Serial Recall** paragraph, followed by an updated figure block + caption.

---

**Revised results paragraph**

Serial recall provides a stringent test of cross‑occurrence competition. In the **data** from @logan2021serial and from @kahana2000interresponse (@fig-serial_rep_crp, top), the **cross‑occurrence forward errors** are rare: after participants correctly report through the first occurrence at position \$i\$, direct transitions to the *second* occurrence’s forward neighbors (\$j{+}1\$ or \$j{+}2\$) occur at rates indistinguishable from the matched control baseline. In other words, the second occurrence’s neighborhood does not attract responses away from the correct continuation. In the **simulations** (bottom of @fig-serial_rep_crp), standard CMR—fitted separately to each dataset—predicts a measurable elevation of these \$i!\rightarrow!j{+}1/j{+}2\$ errors relative to baseline, consistent with blended support across occurrences. The absence of such errors in the human data generalizes the non‑interference pattern from free recall to serial order.

---

**Updated figure block + caption**

```markdown
::: {#fig-serial_rep_crp layout="[[1,1],[1,1]]"}

![](figures/RepeatedRecallsGordonRanschburg2021_mixedvscontrolA_data_full_best_of_3_second_rep_crp.png)

![](figures/RepeatedRecallsKahanaJacobs2000_mixedvscontrolA_data_full_best_of_3_second_rep_crp.png)

![](figures/RepeatedRecallsGordonRanschburg2021_mixedvscontrolA_WeirdCMR_full_best_of_3_second_rep_crp.png)

![](figures/RepeatedRecallsKahanaJacobs2000_mixedvscontrolA_WeirdCMR_full_best_of_3_second_rep_crp.png)

**Cross‑occurrence forward errors in serial recall (two datasets).** **Top row (data):** left—Logan et al. (2021, Exp. 2); right—Kahana & Jacobs (2000; first forward recall after initial study). Each panel plots the conditional probability—**after correct report through the first occurrence at position $i$**—of an erroneous transition to the *second* occurrence’s forward neighbors ($i\!\rightarrow\!j{+}1$ and $i\!\rightarrow\!j{+}2$), contrasting mixed lists with their position‑matched, symmetric baseline. **Bottom row (CMR):** standard CMR simulations fitted separately to each dataset and scored with the identical baseline procedure. In both datasets, data show no elevation of $i\!\rightarrow\!j{+}1/j{+}2$ errors relative to baseline (non‑interference), whereas CMR predicts a clear error elevation (associative blending). All probabilities condition on eligibility (targets exist and have not yet been output).
:::
```

> **Note.** If your computation also includes the **symmetric case** (errors starting from \$j\$ to the first occurrence’s forward neighbors \$i{+}1\$/\$i{+}2\$), adjust the bolded clause to “after correct report through an occurrence, errors to the *other* occurrence’s forward neighbors (\$\ldots\$), pooling over both directions.”
