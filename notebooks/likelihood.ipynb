{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d72ce14-7387-4120-88d7-1f63dfdf6d4e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " # Comparing MixedCMRFactory Implementations (Single-Subject LL Check)\n",
    "\n",
    " In this literate-programming notebook (using `py:percent` cells), we'll:\n",
    "\n",
    " 1. Load a recall dataset (e.g., Healey & Kahana 2014 data).\n",
    " 2. Load a fitted parameter set (from a JSON file).\n",
    " 3. Compare two different `MixedCMRFactory` implementations:\n",
    "    - **Factory A**: `from jaxcmr.cmr import MixedCMRFactory`\n",
    "    - **Factory B**: `from jaxcmr.instance_cmr import MixedCMRFactory`\n",
    "\n",
    " We'll do the comparison for **just the first subject** found in the dataset/fits,\n",
    " computing and comparing a single log-likelihood (LL) value from each factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf548116-29b4-4ed9-8473-32c3b5f7e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Factory A\n",
    "from jaxcmr.cmr import MixedCMRFactory as MixedCMRFactoryA\n",
    "\n",
    "# Factory B\n",
    "from jaxcmr.instance_cmr import MixedCMRFactory as MixedCMRFactoryB\n",
    "\n",
    "from jaxcmr.likelihood import MemorySearchLikelihoodFnGenerator\n",
    "from jaxcmr.helpers import load_data\n",
    "from jax import numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130373a-af19-4c88-8e7a-e1519cfc2fda",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## 1. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9690c4cc-684d-4f0d-9088-6b81bffc40e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset keys: ['listLength', 'listtype', 'pres_itemids', 'pres_itemnos', 'rec_itemids', 'recalls', 'session', 'subject']\n",
      "Number of trials: 14112\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "data_path = \"data/HealeyKahana2014.h5\"\n",
    "data = load_data(data_path)\n",
    "\n",
    "print(\"Dataset keys:\", list(data.keys()))\n",
    "print(\"Number of trials:\", data[\"recalls\"].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a4a40-4823-4ea3-9b5b-47c38a7cd546",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## 2. Load the Fit Results\n",
    "\n",
    " We'll load a JSON file containing the optimized parameters.\n",
    " This could be a multi-subject fit or a single-subject fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49923bd3-a39b-4a8e-b641-50dfae859bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit results keys: ['fixed', 'free', 'fitness', 'fits', 'hyperparameters', 'fit_time', 'data_query', 'model', 'name']\n",
      "Parameter names in fit: dict_keys(['encoding_drift_rate', 'start_drift_rate', 'recall_drift_rate', 'shared_support', 'item_support', 'learning_rate', 'primacy_scale', 'primacy_decay', 'stop_probability_scale', 'stop_probability_growth', 'mcf_trace_sensitivity', 'choice_sensitivity', 'subject'])\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "fit_results_path = os.path.join(\"fits\", \"HealeyKahana2014_InstanceCMR_best_of_1.json\")\n",
    "with open(fit_results_path, \"r\") as f:\n",
    "    fit_results = json.load(f)\n",
    "\n",
    "print(\"Fit results keys:\", list(fit_results.keys()))\n",
    "print(\"Parameter names in fit:\", fit_results[\"fits\"].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e248b-f731-48ee-9aa7-c077a6518875",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## 3. Select the First Subject\n",
    "\n",
    " We assume there's at least one subject. If it's a multi-subject fit, we'll just pick the first subject ID\n",
    " and the corresponding parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d796010-c10e-400f-97bd-15296e7320e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using subject 63\n",
      "Number of trials for subject 63: 112\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "all_subjects = np.unique(data[\"subject\"].flatten())\n",
    "subject_id = all_subjects[0]\n",
    "print(f\"Using subject {subject_id}\")\n",
    "\n",
    "# Create a boolean mask for trials belonging to this subject\n",
    "trial_mask = (data[\"subject\"].flatten() == subject_id)\n",
    "\n",
    "print(f\"Number of trials for subject {subject_id}: {trial_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7e38ed-2d3e-4c07-8109-dfe29789eebb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## 4. Prepare a Connectivity Matrix (If Needed)\n",
    "\n",
    " If no semantic or associative connections are used, we can just supply a zero matrix of the appropriate size.\n",
    " We'll do that here for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99be2e1e-b232-41f7-af62-3368e63f9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "max_itemno = np.max(data[\"pres_itemnos\"])\n",
    "connections = jnp.zeros((max_itemno, max_itemno))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0d7688-809c-4357-bd1b-d342cef872de",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## 5. Extract Parameters for this Subject\n",
    "\n",
    " If the fit is multi-subject, each parameter array in `fit_results[\"fits\"]` will have one entry per subject.\n",
    " We'll extract the entry that corresponds to our `subject_id`.\n",
    "\n",
    " If the fit is single-subject (or a single global fit), we might only have scalars or length-1 arrays.\n",
    " We'll handle that by just indexing safely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a5245cb-1b4e-47ca-b048-95c297495afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject index in the fit arrays: 0\n",
      "Subject parameter dictionary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'encoding_drift_rate': 0.19690460839075208,\n",
       " 'start_drift_rate': 0.13471814445395458,\n",
       " 'recall_drift_rate': 0.9184788152966787,\n",
       " 'shared_support': 75.02002448558682,\n",
       " 'item_support': 98.32965873913969,\n",
       " 'learning_rate': 0.6151140503551014,\n",
       " 'primacy_scale': 53.6643963763364,\n",
       " 'primacy_decay': 0.8904633246586897,\n",
       " 'stop_probability_scale': 0.004061401990797298,\n",
       " 'stop_probability_growth': 0.35607019330468326,\n",
       " 'mcf_trace_sensitivity': 12.16929668644169,\n",
       " 'choice_sensitivity': 1.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "fit_dict = fit_results[\"fits\"]\n",
    "param_names = [k for k in fit_dict.keys() if k not in (\"subject\",)]\n",
    "\n",
    "# First, see if \"subject\" is present in the fits and if its length matches `all_subjects`\n",
    "# If so, we assume multi-subject fits. Otherwise, single-subject.\n",
    "is_multisubject = (\"subject\" in fit_dict) and (len(fit_dict[\"subject\"]) == len(all_subjects))\n",
    "\n",
    "# Find which index in fit_dict[\"subject\"] corresponds to our chosen subject_id\n",
    "if is_multisubject:\n",
    "    # We assume the order in fit_dict[\"subject\"] matches `all_subjects`\n",
    "    subject_index = np.where(np.array(fit_dict[\"subject\"]) == subject_id)[0][0]\n",
    "    print(f\"Subject index in the fit arrays: {subject_index}\")\n",
    "else:\n",
    "    subject_index = None\n",
    "\n",
    "# Build a simple dictionary of param_name -> single float value for the chosen subject\n",
    "params_for_subject = {}\n",
    "for p in param_names:\n",
    "    arr = np.array(fit_dict[p], dtype=float)\n",
    "    if is_multisubject:\n",
    "        value = arr[subject_index]\n",
    "    else:\n",
    "        # Single-subject or single global fit => just use the (0)-th or scalar\n",
    "        value = arr[0] if arr.ndim == 1 else float(arr)\n",
    "    params_for_subject[p] = float(value)\n",
    "\n",
    "print(\"Subject parameter dictionary:\")\n",
    "params_for_subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d72a18-66fc-45ee-83bc-08204204cc0b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## 6. Compute LL with Factory A vs. Factory B\n",
    "\n",
    " We'll define a helper function to compute the negative log-likelihood (NLL) for this subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc68cd6-216a-44b0-aae0-e8c26276dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def compute_nll_for_subject(\n",
    "    data_dict: dict[str, np.ndarray],\n",
    "    connections: jnp.ndarray,\n",
    "    trial_mask: np.ndarray,\n",
    "    subject_params: dict[str, float],\n",
    "    model_factory,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute negative LL for a single subject given their trial_mask and subject_params,\n",
    "    using the specified `model_factory`.\n",
    "    \"\"\"\n",
    "    # Convert boolean trial_mask to integer indices for JAX\n",
    "    trial_indices = jnp.where(trial_mask, size=trial_mask.size)[0]\n",
    "\n",
    "    # Set up the likelihood function generator\n",
    "    generator = MemorySearchLikelihoodFnGenerator(model_factory, data_dict, connections)\n",
    "\n",
    "    # Decide whether to use the \"base\" or \"present_and_predict\" approach\n",
    "    # based on whether all pres_itemnos are identical for this subject's trials.\n",
    "    these_pres = data_dict[\"pres_itemnos\"][trial_mask]\n",
    "    # if all rows identical:\n",
    "    if np.all(np.all(these_pres[0] == these_pres, axis=1)):\n",
    "        nll = generator.base_predict_trials_loss(trial_indices, subject_params)\n",
    "    else:\n",
    "        nll = generator.present_and_predict_trials_loss(trial_indices, subject_params)\n",
    "\n",
    "    return float(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b9af5db-9e26-4e9f-a858-0e30e3197c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "nll_A = compute_nll_for_subject(\n",
    "    data_dict=data,\n",
    "    connections=connections,\n",
    "    trial_mask=trial_mask,\n",
    "    subject_params=params_for_subject,\n",
    "    model_factory=MixedCMRFactoryA,\n",
    ")\n",
    "\n",
    "nll_B = compute_nll_for_subject(\n",
    "    data_dict=data,\n",
    "    connections=connections,\n",
    "    trial_mask=trial_mask,\n",
    "    subject_params=params_for_subject,\n",
    "    model_factory=MixedCMRFactoryB,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75456dee-1d46-4864-a0e6-e0bdac437619",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## 7. Compare the Two LL Values\n",
    "\n",
    " We'll just print them side-by-side and see if they match (to within floating-point tolerance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0298c273-f7a3-492e-985d-5b85877f9d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 63 LL comparison:\n",
      "  Factory A: NLL = 235165.843750\n",
      "  Factory B: NLL = inf\n",
      "  Absolute difference = inf\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print(f\"Subject {subject_id} LL comparison:\")\n",
    "print(f\"  Factory A: NLL = {nll_A:.6f}\")\n",
    "print(f\"  Factory B: NLL = {nll_B:.6f}\")\n",
    "diff = abs(nll_A - nll_B)\n",
    "print(f\"  Absolute difference = {diff:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe02358-0b7d-48d2-abbe-ea7f034e6d57",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " **Conclusion**: If both factory implementations are identical (just housed in different modules),\n",
    " the negative log-likelihood values should be extremely close (differing at most by small numerical round-off).\n",
    " A difference near zero (e.g., < 1e-12) indicates they produce the same LL for this subject."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
